{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import modules\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import gc\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2016 Register to Apply(Boosted Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import data\n",
    "'''\n",
    "df_raw = pd.read_excel('./Data_Processed_All_Contractors_Characteristics.xlsx',sheet=1)\n",
    "df_2016 = df_raw.loc[df_raw['year'] == 2016]\n",
    "df_2016_xy = df_2016.iloc[:,:57].drop(['Dealer ID','No. of Employees','year','JS 17.Column3','JS 18.Column3','JS 19.Column3','NON USER 17.Column3','NON USER 18.Column3','Velocity 17.Column3','centurty 18.Column3','Gibson 18.Column3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['train_test', 'Converted State-AL', 'Converted State-AR',\n",
       "       'Converted State-CA', 'Converted State-FL', 'Converted State-GA',\n",
       "       'Converted State-IL', 'Converted State-IN', 'Converted State-KY',\n",
       "       'Converted State-LA', 'Converted State-MI', 'Converted State-MO',\n",
       "       'Converted State-NC', 'Converted State-NJ', 'Converted State-OH',\n",
       "       'Converted State-Others', 'Converted State-PA', 'Converted State-SC',\n",
       "       'Converted State-TN', 'Converted State-TX', 'employeebucket-NA',\n",
       "       'employeebucket-4~8', 'employeebucket-<4', 'employeebucket->8',\n",
       "       'Sales between 0-99,999', 'Sales between 100,000-499,999',\n",
       "       'Other Sales', 'Sales N/A', 'Currently offers Consumer Financing?_No',\n",
       "       'Currently offers Consumer Financing?_Yes',\n",
       "       'Currently offers Consumer Financing?_N/A', 'Over 10', 'Below 10',\n",
       "       'No year info', 'Hitting Potential 16.Column3', 'JS 16.Column3',\n",
       "       'NON USER 16.Column3', 'brand_1', 'brand_2', 'brand_3', 'brand_4',\n",
       "       'brand_5', 'brand_6', 'brand_7', 'brand_8', 'applied 2016'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016_xy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clarify target and x variables (features and categorical features)\n",
    "'''\n",
    "train_df = df_2016_xy.loc[df_2016_xy['train_test'] == 1].drop('train_test',axis = 1)\n",
    "test_df = df_2016_xy.loc[df_2016_xy['train_test'] == 0].drop('train_test',axis = 1)\n",
    "x_train = train_df.iloc[:,:44]\n",
    "y_train = train_df['applied 2016']\n",
    "x_test = test_df.iloc[:,:44]\n",
    "y_test = test_df['applied 2016']\n",
    "features = [c for c in df_2016_xy.columns if c not in ['applied 2016','train_test']]\n",
    "categorical_feats = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set one function with different parameters to do parameters optimization\n",
    "'''\n",
    "def lgb_cv(num_leaves,\n",
    "           min_data_in_leaf,\n",
    "           max_depth,\n",
    "           feature_fraction,\n",
    "           bagging_fraction,\n",
    "           lambda_l1,\n",
    "          threshold):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(x_train.shape[0])\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                               label=y_train.iloc[trn_idx],\n",
    "                               categorical_feature=categorical_feats\n",
    "                              )\n",
    "        val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                               label=y_train.iloc[val_idx],\n",
    "                               categorical_feature=categorical_feats\n",
    "                              )\n",
    "        param = {\n",
    "            'num_leaves': int(num_leaves),\n",
    "            'min_data_in_leaf': int(min_data_in_leaf), \n",
    "            'objective':'binary',\n",
    "            'max_depth': int(max_depth),\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": feature_fraction,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": bagging_fraction ,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"lambda_l1\": lambda_l1,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "    \n",
    "        clf = lgb.train(param,\n",
    "                        trn_data,\n",
    "                        10000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 50)\n",
    "        \n",
    "        oof[val_idx] = clf.predict(x_train.iloc[val_idx][features],\n",
    "                                   num_iteration=clf.best_iteration)\n",
    "        del clf, trn_idx, val_idx\n",
    "        gc.collect()\n",
    "    \n",
    "    for i in range(x_train.shape[0]):\n",
    "        if oof[i] >= threshold:\n",
    "            oof[i] = 1\n",
    "        else:\n",
    "            oof[i] = 0\n",
    "\n",
    "    return accuracy_score(oof, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use bayesian optimization to find the optimal parameters in ranges\n",
    "'''\n",
    "LGB_BO = BayesianOptimization(lgb_cv, {\n",
    "    'num_leaves': (5, 130),\n",
    "    'min_data_in_leaf': (10, 150),\n",
    "    'max_depth': (4, 10),\n",
    "    'feature_fraction': (1,1),\n",
    "    'bagging_fraction': (1,1),\n",
    "    'lambda_l1': (0, 6),\n",
    "    'threshold':(0.5,0.5),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | max_depth | min_da... | num_le... | threshold |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's binary_logloss: 0.650166\tvalid_1's binary_logloss: 0.679585\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's binary_logloss: 0.654448\tvalid_1's binary_logloss: 0.679091\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.656704\tvalid_1's binary_logloss: 0.690701\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[238]\ttraining's binary_logloss: 0.653951\tvalid_1's binary_logloss: 0.66059\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.683435\tvalid_1's binary_logloss: 0.691488\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5662  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.94    \u001b[0m | \u001b[0m 7.665   \u001b[0m | \u001b[0m 117.6   \u001b[0m | \u001b[0m 81.98   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.659394\tvalid_1's binary_logloss: 0.685017\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's binary_logloss: 0.655047\tvalid_1's binary_logloss: 0.678588\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.656293\tvalid_1's binary_logloss: 0.689952\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's binary_logloss: 0.663922\tvalid_1's binary_logloss: 0.668154\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.682302\tvalid_1's binary_logloss: 0.691696\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5679  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.683   \u001b[0m | \u001b[95m 8.6     \u001b[0m | \u001b[95m 117.7   \u001b[0m | \u001b[95m 39.35   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.632095\tvalid_1's binary_logloss: 0.665222\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.631888\tvalid_1's binary_logloss: 0.668785\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.644516\tvalid_1's binary_logloss: 0.675963\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.646112\tvalid_1's binary_logloss: 0.654673\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.638817\tvalid_1's binary_logloss: 0.671944\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.562   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2965  \u001b[0m | \u001b[0m 6.408   \u001b[0m | \u001b[0m 10.12   \u001b[0m | \u001b[0m 5.183   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[434]\ttraining's binary_logloss: 0.643719\tvalid_1's binary_logloss: 0.673387\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's binary_logloss: 0.644805\tvalid_1's binary_logloss: 0.671517\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.654458\tvalid_1's binary_logloss: 0.689306\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.643418\tvalid_1's binary_logloss: 0.652249\n",
      "Early stopping, best iteration is:\n",
      "[496]\ttraining's binary_logloss: 0.643524\tvalid_1's binary_logloss: 0.651975\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.686323\tvalid_1's binary_logloss: 0.690996\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.5688  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.31    \u001b[0m | \u001b[95m 8.991   \u001b[0m | \u001b[95m 150.0   \u001b[0m | \u001b[95m 5.499   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[203]\ttraining's binary_logloss: 0.662198\tvalid_1's binary_logloss: 0.678588\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's binary_logloss: 0.656898\tvalid_1's binary_logloss: 0.67554\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's binary_logloss: 0.65548\tvalid_1's binary_logloss: 0.68913\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[294]\ttraining's binary_logloss: 0.657673\tvalid_1's binary_logloss: 0.665099\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.686627\tvalid_1's binary_logloss: 0.691394\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5654  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.254   \u001b[0m | \u001b[0m 4.698   \u001b[0m | \u001b[0m 149.9   \u001b[0m | \u001b[0m 5.437   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.645944\tvalid_1's binary_logloss: 0.67451\n",
      "Early stopping, best iteration is:\n",
      "[549]\ttraining's binary_logloss: 0.645248\tvalid_1's binary_logloss: 0.674011\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[312]\ttraining's binary_logloss: 0.646478\tvalid_1's binary_logloss: 0.671542\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.655231\tvalid_1's binary_logloss: 0.689736\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.647183\tvalid_1's binary_logloss: 0.653181\n",
      "Early stopping, best iteration is:\n",
      "[502]\ttraining's binary_logloss: 0.647131\tvalid_1's binary_logloss: 0.653119\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.686614\tvalid_1's binary_logloss: 0.691137\n",
      "| \u001b[95m 6       \u001b[0m | \u001b[95m 0.5739  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 2.422   \u001b[0m | \u001b[95m 9.635   \u001b[0m | \u001b[95m 149.5   \u001b[0m | \u001b[95m 129.3   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[421]\ttraining's binary_logloss: 0.641978\tvalid_1's binary_logloss: 0.672301\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's binary_logloss: 0.644083\tvalid_1's binary_logloss: 0.674727\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.65618\tvalid_1's binary_logloss: 0.690035\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's binary_logloss: 0.645641\tvalid_1's binary_logloss: 0.652259\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.686153\tvalid_1's binary_logloss: 0.690859\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.5756  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.7173  \u001b[0m | \u001b[95m 8.102   \u001b[0m | \u001b[95m 148.8   \u001b[0m | \u001b[95m 129.3   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[369]\ttraining's binary_logloss: 0.642779\tvalid_1's binary_logloss: 0.672778\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's binary_logloss: 0.644082\tvalid_1's binary_logloss: 0.671917\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.655549\tvalid_1's binary_logloss: 0.689867\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[318]\ttraining's binary_logloss: 0.645006\tvalid_1's binary_logloss: 0.653115\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.686937\tvalid_1's binary_logloss: 0.691038\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5705  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2408  \u001b[0m | \u001b[0m 9.961   \u001b[0m | \u001b[0m 149.0   \u001b[0m | \u001b[0m 127.0   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.645036\tvalid_1's binary_logloss: 0.673479\n",
      "Early stopping, best iteration is:\n",
      "[579]\ttraining's binary_logloss: 0.644048\tvalid_1's binary_logloss: 0.673135\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's binary_logloss: 0.656603\tvalid_1's binary_logloss: 0.67653\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.655945\tvalid_1's binary_logloss: 0.689139\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.646688\tvalid_1's binary_logloss: 0.654496\n",
      "Early stopping, best iteration is:\n",
      "[543]\ttraining's binary_logloss: 0.645583\tvalid_1's binary_logloss: 0.65416\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.686546\tvalid_1's binary_logloss: 0.691108\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.132   \u001b[0m | \u001b[0m 4.12    \u001b[0m | \u001b[0m 148.4   \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.616246\tvalid_1's binary_logloss: 0.676456\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.618762\tvalid_1's binary_logloss: 0.671886\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.590782\tvalid_1's binary_logloss: 0.671743\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.605809\tvalid_1's binary_logloss: 0.661981\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.625466\tvalid_1's binary_logloss: 0.682995\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2717  \u001b[0m | \u001b[0m 9.96    \u001b[0m | \u001b[0m 12.88   \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's binary_logloss: 0.663176\tvalid_1's binary_logloss: 0.679144\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[254]\ttraining's binary_logloss: 0.655539\tvalid_1's binary_logloss: 0.67691\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's binary_logloss: 0.65611\tvalid_1's binary_logloss: 0.689574\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's binary_logloss: 0.660754\tvalid_1's binary_logloss: 0.66742\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.685066\tvalid_1's binary_logloss: 0.691138\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5696  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.477   \u001b[0m | \u001b[0m 9.813   \u001b[0m | \u001b[0m 146.7   \u001b[0m | \u001b[0m 125.6   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[83]\ttraining's binary_logloss: 0.661722\tvalid_1's binary_logloss: 0.677522\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's binary_logloss: 0.644921\tvalid_1's binary_logloss: 0.67455\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.654441\tvalid_1's binary_logloss: 0.689326\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[282]\ttraining's binary_logloss: 0.647279\tvalid_1's binary_logloss: 0.65366\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.686086\tvalid_1's binary_logloss: 0.690828\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5696  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.4486  \u001b[0m | \u001b[0m 9.649   \u001b[0m | \u001b[0m 148.9   \u001b[0m | \u001b[0m 126.8   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's binary_logloss: 0.646543\tvalid_1's binary_logloss: 0.675076\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[151]\ttraining's binary_logloss: 0.646667\tvalid_1's binary_logloss: 0.67632\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.652516\tvalid_1's binary_logloss: 0.689104\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's binary_logloss: 0.643069\tvalid_1's binary_logloss: 0.652048\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.684714\tvalid_1's binary_logloss: 0.691043\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5662  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.556   \u001b[0m | \u001b[0m 4.042   \u001b[0m | \u001b[0m 139.9   \u001b[0m | \u001b[0m 127.1   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[183]\ttraining's binary_logloss: 0.664303\tvalid_1's binary_logloss: 0.681183\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's binary_logloss: 0.657725\tvalid_1's binary_logloss: 0.676739\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's binary_logloss: 0.65634\tvalid_1's binary_logloss: 0.689441\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's binary_logloss: 0.660997\tvalid_1's binary_logloss: 0.667622\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.685178\tvalid_1's binary_logloss: 0.691158\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5611  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.78    \u001b[0m | \u001b[0m 9.684   \u001b[0m | \u001b[0m 145.7   \u001b[0m | \u001b[0m 128.7   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.641548\tvalid_1's binary_logloss: 0.665365\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.638749\tvalid_1's binary_logloss: 0.672881\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[62]\ttraining's binary_logloss: 0.644399\tvalid_1's binary_logloss: 0.679673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.648377\tvalid_1's binary_logloss: 0.658247\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.660596\tvalid_1's binary_logloss: 0.678851\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5628  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 68.88   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's binary_logloss: 0.656456\tvalid_1's binary_logloss: 0.676079\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's binary_logloss: 0.644966\tvalid_1's binary_logloss: 0.67446\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.657094\tvalid_1's binary_logloss: 0.689621\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's binary_logloss: 0.645035\tvalid_1's binary_logloss: 0.652807\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.686922\tvalid_1's binary_logloss: 0.691031\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5671  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1742  \u001b[0m | \u001b[0m 8.547   \u001b[0m | \u001b[0m 148.8   \u001b[0m | \u001b[0m 64.64   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.625757\tvalid_1's binary_logloss: 0.676719\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.648853\tvalid_1's binary_logloss: 0.669354\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's binary_logloss: 0.664243\tvalid_1's binary_logloss: 0.687209\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's binary_logloss: 0.627992\tvalid_1's binary_logloss: 0.65176\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's binary_logloss: 0.683104\tvalid_1's binary_logloss: 0.691575\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5577  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.04157 \u001b[0m | \u001b[0m 9.557   \u001b[0m | \u001b[0m 64.45   \u001b[0m | \u001b[0m 42.95   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's binary_logloss: 0.642058\tvalid_1's binary_logloss: 0.67709\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[134]\ttraining's binary_logloss: 0.64341\tvalid_1's binary_logloss: 0.673145\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.657011\tvalid_1's binary_logloss: 0.691036\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's binary_logloss: 0.646421\tvalid_1's binary_logloss: 0.653485\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.681927\tvalid_1's binary_logloss: 0.691211\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5645  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.06874 \u001b[0m | \u001b[0m 4.007   \u001b[0m | \u001b[0m 110.1   \u001b[0m | \u001b[0m 5.397   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.62848\tvalid_1's binary_logloss: 0.668655\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.623023\tvalid_1's binary_logloss: 0.66699\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.619271\tvalid_1's binary_logloss: 0.675087\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's binary_logloss: 0.59681\tvalid_1's binary_logloss: 0.651708\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.632756\tvalid_1's binary_logloss: 0.670252\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.556   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.8647  \u001b[0m | \u001b[0m 4.068   \u001b[0m | \u001b[0m 10.24   \u001b[0m | \u001b[0m 129.9   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.620047\tvalid_1's binary_logloss: 0.68017\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.600027\tvalid_1's binary_logloss: 0.672726\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.598155\tvalid_1's binary_logloss: 0.673608\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.59087\tvalid_1's binary_logloss: 0.666722\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.636219\tvalid_1's binary_logloss: 0.679871\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5696  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1574  \u001b[0m | \u001b[0m 9.939   \u001b[0m | \u001b[0m 11.54   \u001b[0m | \u001b[0m 87.05   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[96]\ttraining's binary_logloss: 0.638033\tvalid_1's binary_logloss: 0.665999\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.63995\tvalid_1's binary_logloss: 0.67472\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.644511\tvalid_1's binary_logloss: 0.681865\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttraining's binary_logloss: 0.646518\tvalid_1's binary_logloss: 0.656383\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.657868\tvalid_1's binary_logloss: 0.682166\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5671  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.976   \u001b[0m | \u001b[0m 9.495   \u001b[0m | \u001b[0m 12.33   \u001b[0m | \u001b[0m 8.325   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's binary_logloss: 0.639167\tvalid_1's binary_logloss: 0.677929\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.633852\tvalid_1's binary_logloss: 0.672768\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's binary_logloss: 0.636654\tvalid_1's binary_logloss: 0.687196\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.642033\tvalid_1's binary_logloss: 0.663983\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's binary_logloss: 0.661818\tvalid_1's binary_logloss: 0.681299\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5696  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.865   \u001b[0m | \u001b[0m 9.985   \u001b[0m | \u001b[0m 39.94   \u001b[0m | \u001b[0m 109.7   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set parameters\n",
    "'''\n",
    "param = {\n",
    "            'num_leaves': 39,\n",
    "            'min_data_in_leaf': 117, \n",
    "            'objective':'binary',\n",
    "            'max_depth': 8,\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 1,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": 1,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"lambda_l1\": 5.683,\n",
    "            \"verbosity\": -1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.659394\tvalid_1's binary_logloss: 0.685017\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's binary_logloss: 0.655046\tvalid_1's binary_logloss: 0.678588\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.656292\tvalid_1's binary_logloss: 0.689952\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's binary_logloss: 0.663921\tvalid_1's binary_logloss: 0.668154\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.682302\tvalid_1's binary_logloss: 0.691696\n",
      "CV score: 0.56791 \n",
      "Test Accuracy:0.58305 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run boosted tree\n",
    "'''\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(x_train))\n",
    "predictions = np.zeros(len(x_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                           label=y_train.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                           label=y_train.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(x_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "pred_0_1 = [0]*len(predictions)\n",
    "for i in range(x_train.shape[0]):\n",
    "        if oof[i] >= 0.5:\n",
    "            oof[i] = 1\n",
    "        else:\n",
    "            oof[i] = 0\n",
    "for i in range(len(predictions)):\n",
    "        if predictions[i] >= 0.5:\n",
    "            pred_0_1[i] = 1\n",
    "        else:\n",
    "            pred_0_1[i] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(accuracy_score(oof, y_train.values)))\n",
    "print(\"Test Accuracy:{:<8.5f}\".format(accuracy_score(pred_0_1, y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test.values, pred_0_1, labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrix_matrix(matrix):\n",
    "    df_matrix=pd.DataFrame(matrix,columns=['pred_0','pred_1'],index=['actual_0','actual_1'])\n",
    "    tn, fp, fn, tp=matrix.ravel()\n",
    "    acc=(tp+tn)/(tp+tn+fp+fn)\n",
    "    ppv=tp/(tp+fp)\n",
    "    npv=tn/(tn+fn)\n",
    "    tpr=tp/(tp+fn)\n",
    "    tnr=tn/(tn+fp)\n",
    "    summary_matrix=[acc,ppv,npv,tpr,tnr]\n",
    "    df_summary=pd.DataFrame(summary_matrix,columns=['Value'],index=['Accuracy','PPV','NPV','Sensitivity','Specificity'])\n",
    "    return df_matrix,df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix,df_summary = metrix_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_0</th>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_1</th>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred_0  pred_1\n",
       "actual_0      70      65\n",
       "actual_1      58     102"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.583051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.610778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.518519</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value\n",
       "Accuracy     0.583051\n",
       "PPV          0.610778\n",
       "NPV          0.546875\n",
       "Sensitivity  0.637500\n",
       "Specificity  0.518519"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractor_id = df_2016.loc[(df_2016['train_test'] == 0),'Dealer ID'].values\n",
    "actual = y_test.values\n",
    "predicted_prob = np.array(predictions)\n",
    "predicted= pred_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=pd.DataFrame()\n",
    "df_result[\"contractor_id\"]=contractor_id\n",
    "df_result[\"actual\"]=actual\n",
    "df_result[\"predicted\"]=predicted\n",
    "df_result[\"predicted_prob\"]=predicted_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TP(columna,columnb):\n",
    "    if columna==1 and columnb==1:\n",
    "        x=1\n",
    "    else:\n",
    "        x=0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=df_result.sort_values(by=[\"predicted_prob\"],ascending=False)\n",
    "df_result[\"Actual_Positive\"]=df_result.apply(lambda x: TP(x[\"actual\"],x[\"predicted\"]),axis=1)\n",
    "df_result[\"Cumulative_Positives\"]=df_result[\"Actual_Positive\"].cumsum()\n",
    "total_positives=df_result[\"Actual_Positive\"].sum()\n",
    "df_result[\"Cumulative_Positives_percent\"]=df_result[\"Cumulative_Positives\"]/total_positives\n",
    "df_result[\"Cumulative_Count\"]=df_result[\"contractor_id\"].expanding().count()/df_result[\"contractor_id\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_result[\"Cumulative_Positives_percent\"].values.tolist())\n",
    "plt.plot(df_result[\"Cumulative_Count\"].values.tolist())\n",
    "plt.ylabel('cumulative Actual Positives Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2017 Register to Apply (Boosted Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2017 = df_raw.loc[df_raw['year'] == 2017]\n",
    "df_2017_xy = df_2017.iloc[:,:58].drop(['Dealer ID','No. of Employees','year','applied 2016','JS 16.Column3','JS 18.Column3','JS 19.Column3','NON USER 16.Column3','NON USER 18.Column3','centurty 18.Column3','Gibson 18.Column3','Hitting Potential 16.Column3'],axis=1)\n",
    "train_df = df_2017_xy.loc[df_2017_xy['train_test'] == 1].drop('train_test',axis = 1)\n",
    "test_df = df_2017_xy.loc[df_2017_xy['train_test'] == 0].drop('train_test',axis = 1)\n",
    "x_train = train_df.iloc[:,:44]\n",
    "y_train = train_df['applied 2017']\n",
    "x_test = test_df.iloc[:,:44]\n",
    "y_test = test_df['applied 2017']\n",
    "features = [c for c in df_2017_xy.columns if c not in ['applied 2017','train_test']]\n",
    "categorical_feats = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | max_depth | min_da... | num_le... | threshold |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.650374\tvalid_1's binary_logloss: 0.686751\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.655931\tvalid_1's binary_logloss: 0.676432\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.66006\tvalid_1's binary_logloss: 0.687122\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.651201\tvalid_1's binary_logloss: 0.677384\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.65617\tvalid_1's binary_logloss: 0.687347\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5649  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.485   \u001b[0m | \u001b[0m 4.302   \u001b[0m | \u001b[0m 12.2    \u001b[0m | \u001b[0m 56.7    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[87]\ttraining's binary_logloss: 0.641618\tvalid_1's binary_logloss: 0.680907\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.659673\tvalid_1's binary_logloss: 0.679667\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.677596\tvalid_1's binary_logloss: 0.687988\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's binary_logloss: 0.622561\tvalid_1's binary_logloss: 0.67165\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.663286\tvalid_1's binary_logloss: 0.685578\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.571   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5192  \u001b[0m | \u001b[0m 7.192   \u001b[0m | \u001b[0m 73.08   \u001b[0m | \u001b[0m 116.2   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.671172\tvalid_1's binary_logloss: 0.685904\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.654317\tvalid_1's binary_logloss: 0.676558\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[11]\ttraining's binary_logloss: 0.67318\tvalid_1's binary_logloss: 0.687199\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's binary_logloss: 0.617765\tvalid_1's binary_logloss: 0.676831\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.675201\tvalid_1's binary_logloss: 0.686514\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.5659  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3248  \u001b[0m | \u001b[0m 9.987   \u001b[0m | \u001b[0m 61.71   \u001b[0m | \u001b[0m 129.5   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[92]\ttraining's binary_logloss: 0.641841\tvalid_1's binary_logloss: 0.680349\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.656627\tvalid_1's binary_logloss: 0.67954\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.679318\tvalid_1's binary_logloss: 0.690233\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[359]\ttraining's binary_logloss: 0.616559\tvalid_1's binary_logloss: 0.681204\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.661175\tvalid_1's binary_logloss: 0.68465\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5629  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1703  \u001b[0m | \u001b[0m 9.906   \u001b[0m | \u001b[0m 77.46   \u001b[0m | \u001b[0m 98.63   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.664954\tvalid_1's binary_logloss: 0.682621\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's binary_logloss: 0.660227\tvalid_1's binary_logloss: 0.680215\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.672652\tvalid_1's binary_logloss: 0.690228\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.668517\tvalid_1's binary_logloss: 0.682089\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.675176\tvalid_1's binary_logloss: 0.686731\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.5578  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.49    \u001b[0m | \u001b[0m 9.99    \u001b[0m | \u001b[0m 58.73   \u001b[0m | \u001b[0m 5.184   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.647679\tvalid_1's binary_logloss: 0.684209\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.653912\tvalid_1's binary_logloss: 0.674688\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's binary_logloss: 0.678459\tvalid_1's binary_logloss: 0.689018\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.644446\tvalid_1's binary_logloss: 0.676368\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's binary_logloss: 0.647077\tvalid_1's binary_logloss: 0.685207\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5527  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.578   \u001b[0m | \u001b[0m 9.848   \u001b[0m | \u001b[0m 10.25   \u001b[0m | \u001b[0m 44.38   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.658037\tvalid_1's binary_logloss: 0.686704\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.646944\tvalid_1's binary_logloss: 0.678348\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's binary_logloss: 0.670319\tvalid_1's binary_logloss: 0.690075\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's binary_logloss: 0.611929\tvalid_1's binary_logloss: 0.674129\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.682373\tvalid_1's binary_logloss: 0.69226\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2103  \u001b[0m | \u001b[0m 4.401   \u001b[0m | \u001b[0m 38.72   \u001b[0m | \u001b[0m 95.86   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.665458\tvalid_1's binary_logloss: 0.683564\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.662846\tvalid_1's binary_logloss: 0.681216\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's binary_logloss: 0.68558\tvalid_1's binary_logloss: 0.691714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.665417\tvalid_1's binary_logloss: 0.683028\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.671187\tvalid_1's binary_logloss: 0.685045\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5527  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.982   \u001b[0m | \u001b[0m 4.283   \u001b[0m | \u001b[0m 31.07   \u001b[0m | \u001b[0m 6.034   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.673532\tvalid_1's binary_logloss: 0.683539\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's binary_logloss: 0.667048\tvalid_1's binary_logloss: 0.684744\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's binary_logloss: 0.686353\tvalid_1's binary_logloss: 0.691591\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's binary_logloss: 0.672131\tvalid_1's binary_logloss: 0.683854\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.67142\tvalid_1's binary_logloss: 0.686038\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5416  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.654   \u001b[0m | \u001b[0m 9.939   \u001b[0m | \u001b[0m 122.9   \u001b[0m | \u001b[0m 5.826   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.677047\tvalid_1's binary_logloss: 0.685212\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.680702\tvalid_1's binary_logloss: 0.690573\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.692025\tvalid_1's binary_logloss: 0.694405\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.674552\tvalid_1's binary_logloss: 0.682124\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.674586\tvalid_1's binary_logloss: 0.684876\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5213  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.868   \u001b[0m | \u001b[0m 4.2     \u001b[0m | \u001b[0m 149.6   \u001b[0m | \u001b[0m 42.73   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's binary_logloss: 0.670267\tvalid_1's binary_logloss: 0.683287\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.679964\tvalid_1's binary_logloss: 0.690556\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttraining's binary_logloss: 0.692019\tvalid_1's binary_logloss: 0.694406\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's binary_logloss: 0.672446\tvalid_1's binary_logloss: 0.681871\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[130]\ttraining's binary_logloss: 0.674172\tvalid_1's binary_logloss: 0.684808\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.5213  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.776   \u001b[0m | \u001b[0m 9.867   \u001b[0m | \u001b[0m 147.2   \u001b[0m | \u001b[0m 87.42   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.666932\tvalid_1's binary_logloss: 0.682491\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's binary_logloss: 0.641445\tvalid_1's binary_logloss: 0.679457\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's binary_logloss: 0.672883\tvalid_1's binary_logloss: 0.68873\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's binary_logloss: 0.672603\tvalid_1's binary_logloss: 0.684853\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.677588\tvalid_1's binary_logloss: 0.686405\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.5467  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1039  \u001b[0m | \u001b[0m 4.044   \u001b[0m | \u001b[0m 110.4   \u001b[0m | \u001b[0m 52.53   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.665739\tvalid_1's binary_logloss: 0.682026\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's binary_logloss: 0.65417\tvalid_1's binary_logloss: 0.6815\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.678075\tvalid_1's binary_logloss: 0.689403\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.673579\tvalid_1's binary_logloss: 0.685608\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's binary_logloss: 0.65082\tvalid_1's binary_logloss: 0.68502\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.5527  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.184   \u001b[0m | \u001b[0m 8.814   \u001b[0m | \u001b[0m 108.4   \u001b[0m | \u001b[0m 108.3   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.669719\tvalid_1's binary_logloss: 0.684339\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[326]\ttraining's binary_logloss: 0.647971\tvalid_1's binary_logloss: 0.676875\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.67677\tvalid_1's binary_logloss: 0.689436\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[128]\ttraining's binary_logloss: 0.662108\tvalid_1's binary_logloss: 0.680817\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's binary_logloss: 0.663033\tvalid_1's binary_logloss: 0.684638\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.5436  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.3965  \u001b[0m | \u001b[0m 9.978   \u001b[0m | \u001b[0m 134.0   \u001b[0m | \u001b[0m 60.7    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.670251\tvalid_1's binary_logloss: 0.682915\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.663753\tvalid_1's binary_logloss: 0.683046\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.676985\tvalid_1's binary_logloss: 0.69017\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[79]\ttraining's binary_logloss: 0.670762\tvalid_1's binary_logloss: 0.683851\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.672855\tvalid_1's binary_logloss: 0.685139\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.5467  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.945   \u001b[0m | \u001b[0m 4.802   \u001b[0m | \u001b[0m 87.44   \u001b[0m | \u001b[0m 24.64   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.662151\tvalid_1's binary_logloss: 0.684\n",
      "fold n°1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's binary_logloss: 0.658207\tvalid_1's binary_logloss: 0.677383\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's binary_logloss: 0.67751\tvalid_1's binary_logloss: 0.687683\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.662059\tvalid_1's binary_logloss: 0.681521\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's binary_logloss: 0.671864\tvalid_1's binary_logloss: 0.686201\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.5588  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.851   \u001b[0m | \u001b[0m 9.752   \u001b[0m | \u001b[0m 36.39   \u001b[0m | \u001b[0m 59.94   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.672647\tvalid_1's binary_logloss: 0.683888\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[127]\ttraining's binary_logloss: 0.667259\tvalid_1's binary_logloss: 0.683822\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's binary_logloss: 0.68513\tvalid_1's binary_logloss: 0.69192\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's binary_logloss: 0.670473\tvalid_1's binary_logloss: 0.683317\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[55]\ttraining's binary_logloss: 0.674273\tvalid_1's binary_logloss: 0.685779\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.5446  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.922   \u001b[0m | \u001b[0m 4.045   \u001b[0m | \u001b[0m 97.04   \u001b[0m | \u001b[0m 85.0    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's binary_logloss: 0.668252\tvalid_1's binary_logloss: 0.682414\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's binary_logloss: 0.651911\tvalid_1's binary_logloss: 0.680797\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.678038\tvalid_1's binary_logloss: 0.690748\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.671394\tvalid_1's binary_logloss: 0.685461\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.659068\tvalid_1's binary_logloss: 0.685447\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.5406  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1791  \u001b[0m | \u001b[0m 9.976   \u001b[0m | \u001b[0m 106.3   \u001b[0m | \u001b[0m 29.4    \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.649044\tvalid_1's binary_logloss: 0.683153\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.655091\tvalid_1's binary_logloss: 0.675328\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's binary_logloss: 0.675419\tvalid_1's binary_logloss: 0.689877\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's binary_logloss: 0.661298\tvalid_1's binary_logloss: 0.677796\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's binary_logloss: 0.648823\tvalid_1's binary_logloss: 0.684423\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.5578  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.859   \u001b[0m | \u001b[0m 9.959   \u001b[0m | \u001b[0m 10.93   \u001b[0m | \u001b[0m 110.0   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.663202\tvalid_1's binary_logloss: 0.68507\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.645296\tvalid_1's binary_logloss: 0.676897\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's binary_logloss: 0.663932\tvalid_1's binary_logloss: 0.687853\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's binary_logloss: 0.617838\tvalid_1's binary_logloss: 0.675597\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.671962\tvalid_1's binary_logloss: 0.688175\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.5598  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.1645  \u001b[0m | \u001b[0m 9.991   \u001b[0m | \u001b[0m 56.16   \u001b[0m | \u001b[0m 112.4   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttraining's binary_logloss: 0.662077\tvalid_1's binary_logloss: 0.684485\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[57]\ttraining's binary_logloss: 0.655663\tvalid_1's binary_logloss: 0.678595\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's binary_logloss: 0.677203\tvalid_1's binary_logloss: 0.688225\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.656261\tvalid_1's binary_logloss: 0.682704\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's binary_logloss: 0.657331\tvalid_1's binary_logloss: 0.683919\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.571   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.602   \u001b[0m | \u001b[0m 9.299   \u001b[0m | \u001b[0m 27.24   \u001b[0m | \u001b[0m 129.9   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.67007\tvalid_1's binary_logloss: 0.682897\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's binary_logloss: 0.66259\tvalid_1's binary_logloss: 0.682554\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.680203\tvalid_1's binary_logloss: 0.69093\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.670462\tvalid_1's binary_logloss: 0.684249\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.67457\tvalid_1's binary_logloss: 0.685859\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.5446  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.96    \u001b[0m | \u001b[0m 9.88    \u001b[0m | \u001b[0m 94.8    \u001b[0m | \u001b[0m 52.97   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set parameters\n",
    "'''\n",
    "param = {\n",
    "            'num_leaves': 52,\n",
    "            'min_data_in_leaf': 94, \n",
    "            'objective':'binary',\n",
    "            'max_depth': 9,\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 1,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": 1,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"lambda_l1\": 5.96,\n",
    "            \"verbosity\": -1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.670071\tvalid_1's binary_logloss: 0.682897\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's binary_logloss: 0.66259\tvalid_1's binary_logloss: 0.682554\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's binary_logloss: 0.680203\tvalid_1's binary_logloss: 0.69093\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[82]\ttraining's binary_logloss: 0.670462\tvalid_1's binary_logloss: 0.684249\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.674571\tvalid_1's binary_logloss: 0.685859\n",
      "CV score: 0.54462 \n",
      "Test Accuracy:0.57490 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run boosted tree\n",
    "'''\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(x_train))\n",
    "predictions = np.zeros(len(x_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                           label=y_train.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                           label=y_train.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(x_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "pred_0_1 = [0]*len(predictions)\n",
    "for i in range(x_train.shape[0]):\n",
    "        if oof[i] >= 0.5:\n",
    "            oof[i] = 1\n",
    "        else:\n",
    "            oof[i] = 0\n",
    "for i in range(len(predictions)):\n",
    "        if predictions[i] >= 0.5:\n",
    "            pred_0_1[i] = 1\n",
    "        else:\n",
    "            pred_0_1[i] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(accuracy_score(oof, y_train.values)))\n",
    "print(\"Test Accuracy:{:<8.5f}\".format(accuracy_score(pred_0_1, y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test.values, pred_0_1, labels=None, sample_weight=None)\n",
    "df_matrix,df_summary = metrix_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_0</th>\n",
       "      <td>84</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_1</th>\n",
       "      <td>63</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred_0  pred_1\n",
       "actual_0      84      42\n",
       "actual_1      63      58"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.574899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.479339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value\n",
       "Accuracy     0.574899\n",
       "PPV          0.580000\n",
       "NPV          0.571429\n",
       "Sensitivity  0.479339\n",
       "Specificity  0.666667"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractor_id = df_2017.loc[(df_2017['train_test'] == 0),'Dealer ID'].values\n",
    "actual = y_test.values\n",
    "predicted_prob = np.array(predictions)\n",
    "predicted= pred_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAD8CAYAAACYebj1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xd8FWX2x/HPSSD03ntHpCggUi1YkCLS7N21/VxFF113xbLq6rqurmV1LSuW1dW1SwlIs4INpIQiIL3lhhIgtED6+f0xl+wlkGQSMplbzvv14pU7t57xYg4zzzzfR1QVY4wxBiDO7wKMMcaED2sKxhhj8llTMMYYk8+agjHGmHzWFIwxxuSzpmCMMSafNQVjjDH5rCkYY4zJZ03BGGNMvgp+F1BS9evX19atW/tdhjHGRJRFixbtUtUGxT0v4ppC69atWbhwod9lGGNMRBGRzW6eZ6ePjDHG5LOmYIwxJp81BWOMMfmsKRhjjMlnTcEYY0w+z5qCiLwlIjtF5JdCHhcReVFE1onIMhHp6VUtxhhj3PHySOFtYEgRjw8FOgT/3Aq86mEtxhhjXPBsnoKqzhWR1kU8ZSTwH3XWA50nIrVFpImqbvOqJhMbJicF2JB60O8yjCkzFXIP02/rG1Q74zY6d+7q7Wd5+u5FawZsDdlODt53TFMQkVtxjiZo2bJluRRnIlNy2iHGfbQEABGfizGmDPSXX3iy4uu0lFTm/9ISorgpHO9/WT3eE1V1AjABoFevXsd9jjEAU5akAPDdH8+hRd2qPldjzAk4nAazH4Kk96BuOxjxNn1an+H5xxbbFESkI875/kaq2lVETgFGqOpfTvCzk4EWIdvNgZQTfE8To1SV3elZTFycTO/Wda0hmMi2MhGm3wvpu2DAOBg4HipWKZePdjPQ/DpwP5ANoKrLgCvK4LMTgeuCVyH1BfbZeIIprf/O30Kvv3zJ+tR0Rvds5nc5xpTOgR3w0bXw8bVQvSHc8jUM+nO5NQRwd/qoqqr+LEefoM0p7kUi8gEwEKgvIsnAI0BFAFX9FzAdGAasAw4BvylR5caE+ODnLbRvWJ3bzm7HiFOb+l2OMSWjCkveh1kPQPZhOO8R6H8nxFcs91LcNIVdItKO4Pl+EbmE4wwGF6SqVxbzuAJ3uCnSmKKs2XGAFSn7eXh4Zy45rbnf5RhTMmmbYOo42PANtOwHI/4J9Tv4Vo6bpnAHziBvJxEJABuBazytyphCfLlyBx8u2HrUfclph4iPE0Z0tyMEE0HycmH+a/D14yBxcOGzcNqNEOdv0ESxTUFVNwDni0g1IE5VD3hfljHHUlX+OmMVe9KzaFrrf+dY40S45cy21K9eycfqjCmBnatgylgILIQOg2H4c1ArPI5y3Vx9dE+BbYB9wCJVXeJRXcYcY3lgHxtS03lyTDeu7G3zVUwEysmC75+Duc9A5Zow5g3odklYTapxc/qoV/DP1OD2hcAC4DYR+URVn/aqOGNCTVwcIKFCHMO6NfG7FGNKLnkhJN4JO1dCt0thyN+gWn2/qzqGm6ZQD+ipqgcBROQR4FPgLGARYE3BeC47N4+pS1M4/+SG1KpS/ldkGFNqWenw9RMw7xWo2RSu+hg6Dva7qkK5aQotgayQ7WyglaoeFpFMb8oy5mjfrU1ld3oWo3uEx3lXY1xZ/w1M/R3s3Qy9boLzH3VOG4UxN03hfZzAuinB7YuAD4IDzys9q8yYEBMXB6hTtSJnd2zgdynGFC80oqJee7hhOrQe4HdVrri5+uhxEZkBDMDJK7pNVRcGH77ay+KMAdifkc0XK3dw+ektSKhg60KZMBcaUXHGPXD2fVCxst9VueYqEE9VF4rIFqAygIi0VNUtnlZmTNDM5dvJzMljdA+LrzBh7MB2pxmsmgqNT4GrP4Emp/pdVYm5uSR1BPAs0BTYiTPG8CvQxdvSjHFMTEqmTf1qdG9R2+9SjDmWqnOaaPaDkJ3hjBv0G+tLREVZcHOk8DjQF/hSVXuIyDlAkREWxpSVwN7DzNuwh7vP74iE0bXcxgCwZyNMGwcbvoVWA+CiF6F+e7+rOiFumkK2qu4WkTgRiVPVb0TkKc8rMwaYsiQAYKeOTHjJy4X5/4Kv/wISDxc+B6f9xveIirLgpinsFZHqwFzgvyKyExcpqcacKFVl0uIAvVrVoWU9Wx/BhIkdK51JaGEYUVEW3LS1kTjR1ncDM4H1wHAvizIGYEXKftbuPGjrI5jwkJMJ3zwJr50FaRvh4jfhqo+iqiGAuyOFh1X1PiAPeAcgeProPi8LM2bi4gAJ8XEM72bpp8ZnWxdA4lhI/RW6XRaMqKjnd1WecHOkMOg49w0t60KMCZWTm0fi0hTO7dSQWlUj8yoOEwWy0mHm/fDmIMg8CFd9Ahe/HrUNAYo4UhCR3wK3A21FZFnIQzWAH7wuzMS279btYtfBTDt1ZPyz/huYehfs3QKn3+yshhbmERVloajTR+8DM4AngfEh9x9Q1T2eVmViVl6e8tTMX/nq153UrlqRc05q6HdJJtYcToNZD8GSYETFb2ZAq/5+V1VuCm0KqroPZ92EK0UkHmgUfH51EaluM5qNF+Zv3MNrczfQtFZlbh/YzmItTPlaOQU+vxcO7Y7IiIqy4GZG81jgUWAHzmAzOOs1n+JdWSZWTUpKplpCPF/9fiBVEuL9LsfEigPb4fPfw6/TnGiKaz6DJrH5K87N1UfjgJNUdbfXxZjYs2lXOjv2ZwCQpzBj+XaGdG1iDcGUj9CIipxMOP/PwYgKV7FwUcnNnm/FOY1kTJlKS89i8D/mkpmTd9T9l5wWXdd9mzC1Z6Oz1sHGOVETUVEW3DSFDcC3IvI5kL+ojqo+51lVJiZMW5ZCZk4ez19+Ko1qOOdtq1WqwKkWfGe8lJcL8151IiriKsDw56HnDVERUVEW3DSFLcE/CcE/xpSJiUkBOjWuYaupmfKzY6UzCS2wCDoOcTKLatllz6HcLLLzZwARqaaq6d6XZGLBxl3pJG3Zy/ihnfwuxcSCnEz47ln47jmoXMuJqOh6MVjy7jHcXH3UD3gTqA60FJFTgf9T1du9Ls5Er0lJAURgZHeLsDAeC42oOOVyGPxkVM9IPlFuTh/9AxgMJAKo6lIROcvTqkxUU1UmJwXo364eTWpV8bscE60yDzrjBvP/BTWbwdWfQofjpfaYUG6X49xaYIGTXG/KMdFs7ppUNqQeZNfBLLbsOcRd53XwuyQTrdZ9BVPHwb4tcPotcP4jUKmG31VFBFeXpIpIf0BFJAG4C1jlbVkm2uw6mMmNby8gJ08BqFstgSFdG/tclYk6h/bA7IdgyX+hXgf4zUxo1c/vqiKKm6ZwG/AC0AxIBmYDd3hZlIk+U5emkJOnTLy9P23qVaNKQjyVK9oENVNGVJ2Iiul/cCIqzrwXzvpDzEVUlAU3Vx/tAq4uzZuLyBCchhIPvKGqfyvweEucNRpqB58zXlWnl+azTPjKzVMmJQXo0rQmPVvW8bscE232b4Pp91pERRkpdraGiLwjIrVDtuuIyFsuXhcPvIyz9kJnnGC9zgWe9hDwsar2AK4AXilJ8Sb8TV2aQvsHp7MseZ+ts2zKliosegde7gPrvoRBj8HNX1tDOEFuTh+doqp7j2yoapqI9HDxut7AOlXdACAiH+Is7bky5DkKHAkorwWkuKraRIx3522maa0qXNevFVf1ael3OSZa7NkQjKiYC63OgBEvQr12flcVFdw0hTgRqaOqaQAiUtfl65rh5CYdkQz0KfCcR4HZInInUA0438X7mgixdc8hft64h98P6sj/nW3/w5oykJcL816Br5+A+Iow/B/Q83qLqChDbn65Pwv8KCKf4vzL/jLgCRevO95UQS2wfSXwtqo+G5wk966IdFXVoxLSRORW4FaAli3tX5vhLDs3j2dmr2ZvejYbdzsT4EfZaSNTFnasgCljIWUxdBwKw5+Dmjb5say5GWj+j4gsBM7F+UU/RlVXFvMycI4MWoRsN+fY00M3AUOCn/OTiFQG6gM7C9QwAZgA0KtXr4KNxYSRr1bt4LU5G6hfvRIV4oRLTmtOi7pV/S7LRLKcTJj7DHz/HFSuDZe8BV3GWESFR4psCiISByxT1a4cPRbgxgKgg4i0AQI4A8lXFXjOFuA84G0RORmoDKSW8HNMGJm4OECDGpX4afy5VIi3Q3pzgrb+7Bwd7FoNp1wBQ56EqnX9riqqFdkUVDVPRJaKSMuSLr+pqjnBVdtm4Vxu+paqrhCRx4CFqpoI/B54XUTuxjm1dIOq2pFAhNl9MJOUvRlk5OTyzeqdXNevtTUEc2IyD8LXj8P816BWc7j6M+hgQ47lwc2YQhNghYj8DOSnpKrqiOJeGJxzML3AfQ+H3F4JDHBdrQk7eXnKmFd/ZPPuQ/n3jelpYwjmBORHVGyF3rfAeQ9bREU5ctMU/ux5FSZi/bxpD5t3H+LOc9tzavPa1KlWkS5Na/ldlolEh/bArAdh6ftQvyPcOBNa9vW7qpjjZqB5joi0Ajqo6pciUhXndJAxTFocoFpCPLcPbG/rKpvSUYWVk52IisNpFlHhMzfrKdyCczloXaAdzvyDf+EMEJsYtT71IPd9uozlgX0MP6WpNQRTOvu3wee/h9WfQ5PucO0kaNzN76pimpvTR3fgzE6eD6Cqa0WkoadVmbD37k+bWZa8j7M6NuDWs9r6XY6JNKqw+D8w+0+QmwmDHoe+t0O8qzR/4yE330CmqmYdWU9BRCpw7CQ0E0Oyc/OYujSFQZ0b8fLVPf0ux0Sa3eudiIpN30HrM+GiFyyiIoy4aQpzROQBoIqIDAJuB6Z6W5YJV6u27Wfq0hR2p2dZwJ0pmdwcJ6Lim786ERUXvQA9rrOIijDjpimMx5l5vBz4P5xLTN/wsigTnnLzlBvfXsC2fRk0rlmZs09q4HdJJlJs/8VZJzklCU4aBhc+axEVYaq4Gc09cAaXv1fV18unJBOu5m3YzbZ9Gfx1dDdGdm9KRZugZoqTkwlz/w7fPw9V6sAl/4Yuoy2iIowV2hRE5GHgGmAR8LSIPGmNIbZNXBygRqUKjOnZzFZNM8XbMh8S73QiKk69Egb/1SIqIkBRRwqXA91V9ZCI1ANmAtYUotyG1IOMfuVHDmXlHPNYdq5yea8W1hBM0TIPwlePwc8TLKIiAhXVFDJU9RCAqu4OhuOZKPfRwq2kZ+Zw85ltiStwhB8fJ1zR26LLTRHWfgnTxsG+ZOh9K5z3J4uoiDBFNYV2IpIYvC0Ftl1lH5nIkpunTElK4eyODRg/tJPf5ZhIcmgPzHoAln4QjKiYBS0LrqllIkFRTWFkge1nvCzE+G/eht1s35/BQ8NP9rsUEylUYcUkmPFHJ6LirD/CWfdChUp+V2ZKqdCmoKpzyrMQ478jA8nnn9zI71JMJNifEoyomA5Ne8C1k6FxV7+rMifI5pQbAA5n5TLzl20MP6WpDSSbouXlweJ34IuHITcbLvgL9PmtRVRECfsWDQCzV24nPSvX1lM2RSsYUTHiRahr2VfRpERNIXgFUnVV3e9RPcYnExcHaFa7Cn3a2HXk5jjyIyqegPhKcNGL0PM6m4QWhYq9zFRE3heRmiJSDWed5tUi8gfvSzPlZeeBDL5bm8rI7k2JK3gdqjHbl8Mb58EXf4J258Ed8+G0660hRCk3cw86B48MRuHkHrUErvW0KlOuEpekkKe2jKYpIDsDvnocJgyE/QG49G244r9Qs4nflRkPuTl9VFFEKuI0hZdUNVtELDo7ikxKCtCtWS3aN7RJRiZoy7xgRMUaOPUqGPyERVTECDdHCq8Bm4BqwNzg0pw2phAl1uw4wIqU/RaDbRyZB5xlMd8a4hwpXPMZjH7VGkIMcbNG84vAiyF3bRaRc7wryZSniYsDxMcJI7pbjHHMC42o6PN/cO6foFJ1v6sy5czNGs2NgL8CTVV1qIh0BvoBb3pdnPHO4axcvlm9k8lJAc7qUJ/61W0Gasw6tAdm3g/LPoT6J8FNs6FFb7+rMj5xc/robWAWcOSfkmuAcV4VZMrH699t4Pb/Lmb7/gwuP72F3+UYP6jCL5/BS6fDL586ERW3fWcNIca5GWiur6ofi8j9AKqaIyK5HtdlPKSqTFycTO/WdXn2slNpXqeK3yWZ8nZUREVPGDHFIioM4K4ppAfXU1AAEekL7PO0KuOppK172bT7ELef054Wdav6XY4pT8dEVDwBfX8LcRZtYhxumsLvgUSc6OwfgAbAJZ5WZcpcWnoWo1/5gT3pWWTl5lGpQhxDuzb2uyxTnnavh8S7YPP30OYsuOgFi6gwx3Bz9dEiETkbOAlnXYXVqprteWWmTE1dlsKm3Ye4sncLKlWIp2erOtSoXNHvskx5yM2Bn16Cb590IipG/BN6XGszks1xubn6aCnwEfCRqq73viTjhYmLA3RqXIMnx5zidymmPG1fDlPugG1LodNwGPaMzUg2RXJz9dEIIAf4WEQWiMi9ImJrMkaQDakHWbJ1r8VYxJLsDGed5AkDYf82uPQduPw9awimWMU2BVXdrKpPq+ppwFXAKcBGzyszZWZyUoA4gZHdrSnEhM0/wb/OgO+ehVMudwLsuoyy00XGFTdHCohIaxH5I/Ah0An4o8vXDRGR1SKyTkTGF/Kcy0RkpYisEJH3XVduXFFVJi0JMKB9fRrVrOx3OcZLmQfg83vh30MgNxOumQijXrGIClMibsYU5gMVgU+AS1V1g5s3FpF44GVgEJAMLBCRRFVdGfKcDsD9wABVTRORhqXYB1OEhZvT2LrnMHef39HvUoyX1n4BU8c5aaZ9fgvnPmQRFaZU3FySer2q/lqK9+4NrDvSRETkQ2AkzpoMR9wCvKyqaQCqurMUn2OKMHFxgCoV4xncxS4/jUrpu2HW/bDsI2jQySIqzAkrtCmIyDWq+h4wTESGFXxcVZ8r5r2bAVtDtpOBPgWe0zH4WT8A8cCjqjrzOLXcCtwK0LKljXG7lZGdy+fLUhjStTHVKtnKq1HlSETFjPsgYx+cPR7OvAcqWIaVOTFF/aaoFvx5vJB9N+spHG9Uq+DrKgAdgIFAc+A7EemqqnuPepHqBGACQK9evWwtB5e++XUn+zNyLBY72uwLwOf3wJqZTkTFyJegURe/qzJRotCmoKqvBW9+qao/hD4mIgNcvHcyEJq01hxIOc5z5gUnw20UkdU4TWKBi/c3xZiYFKBhjUoMaF/f71JMWcjLg0X/hi8egbwci6gwnnBz9dE/Xd5X0AKgg4i0EZEE4AqcuIxQk4FzAESkPs7pJFcD2aZoaelZfLt6JyO7NyXe1l2OfLvXwzvDnSOEZj3g9p+g/1hrCKbMFTWm0A/oDzQQkXtCHqqJc/6/SME01bE4sdvxwFuqukJEHgMWqmpi8LELRGQlkAv8QVV3l353zBHTlqWQnauMslNHke2YiIqXoMc1NufAeKaoMYUEoHrwOaHjCvtxGYinqtOB6QXuezjktgL3BP+YMjQxKcBJjWrQuUlNv0sxpbVtGSSO/V9ExYXPQg27isx4q6gxhTnAHBF5W1U3l2NN5gRt3JVO0pa9jB/aCbF/UUae7AyY8xT88AJUrQeX/Qc6j/S7KhMjijp99A9VHQe8JCLHXPGjqiM8rcyU2qSkACIw0tZdjjybf3KODnavg+7XwAWP24xkU66KOn30bvDnM+VRiCkbqsrkpAD929WjSS1bUS1iZOyHr/4MC96A2i3h2knQ7ly/qzIxqKjTR4uCP+ccuU9E6gAtVHVZOdRmSmHR5jS27DnEXed18LsU49aa2TDtbieiou/tTkRFQrXiX2eMB9xkH32LE59dAVgCpIrIHFW1weEwNDEpQOWKcQyxVdXCX/pumDkeln8cjKj4Alqc7ndVJsa5yT6opar7ReRm4N+q+oiI2JFCGMrMyeXzZdsY3KUx1S3WInzlR1T80TltZBEVJoy4+c1RQUSaAJcBD3pcjyml+Rt2MykpwL7D2RZrEc5CIyqanebMO2jU2e+qjMnnpik8hjPJ7AdVXSAibYG13pZlSiInN4+xHySReiCTtg2qcYbFWoSf0IgKzYXBT0Kf/7MZySbsFNsUVPUTnLUUjmxvAC72sihTMt+v20XqgUxeubonQ7s2trkJ4WbXOph6F2z+AdoOhItegDqtfS7KmONzM9DcHCfraABOyun3wO9UNdnj2owLBzNz+HRRMrWqVOS8kxtaQwgnudnw4z/h279Bxcow8mXofrVFVJiw5ub00b+B94FLg9vXBO8b5FVRxp3FW9K45NUfyVO4qk9LKlWwUxFhY9tSmDIWti+Dk0fAsL9bRIWJCG6aQgNV/XfI9tsiMs6rgox7H/28lcoV47l/aCeGdmvidzkGIPtwMKLiRahWHy57Fzrb5H8TOdw0hV0icg3wQXD7SsCSTH2WkZ3L9OXbGNK1Mdf2a+13OQZg84+QeKcTUdHjGrjgL1Cljt9VGVMibprCjcBLwPM4Ywo/Bu8zPvpy1Q4OZOYwpkdzv0sxGfvhy0dh4ZtQuxVcOxnaneN3VcaUipumcMjC78LPpMUBGtWsRL929fwuJbatmeVEVBzYBn3vgHMftIgKE9EKXXlNRC4SkVRguYgki0j/cqzLFGH3wUzmrEllVPdmtqqaX9J3wWc3w/uXQaWaTkTFkL9aQzARr6gjhSeAM1X1VxHpAzwNnF0+ZZmiTFu2jZw8ZXRPm7lc7lRh+acw8z7ntNHAB+CMu6FCgt+VGVMmimoKOar6K4CqzheRGkU815SjiUkBTm5Sk06NbVW1crUvGabdA2tnQbNeMPIlaHiy31UZU6aKagoNC6zNfNS2qj7nXVmmMOtTD7J0614eHGa/jMpNXh4segu+eNQiKkzUK6opvM7RazMX3DY+mJwUIM5WVSs/u9ZC4l2w5UeLqDAxoahFdv5cnoWY4uXlKZOSAgxoX5+GNSv7XU50Oyai4hXofpVFVJioZ6H7EWTh5jSS0w5zz6COfpcS3VKWOOskb18OnUfC0L9DjUZ+V2VMubCmEEEmJSVTpWI8g7tYho4nsg87RwY//tOJqLj8PTj5Ir+rMqZcWVOIEBnZuUxb5sRaVLNV1creph+ciIo966HHtXDB4xZRYWJSob9dClx5dAy7+qh8ff3rTg5k5NiqamUtYz98+QgsfMsZQL5uijOgbEyMKuqfnHalURiZlBSgYY1KDLBV1crO6pnO0pgHtkG/sXDOAzYj2cQ8u/ooAqSlZ/Ht6p3c0L+1xVqUhfRdMOM++OVTaNjZibdufprfVRkTFtysvFYZuAnoAuRfB6mqlpRaTqYtSyE7VxltiagnRhWWf+I0hMwDFlFhzHEUGogX4l2gMTAYmAM0Bw54WZQ52sSkAJ0a16BzU4u1KLV9yU543cRboF47uO07GHifNQRjCnDTFNqr6p+AdFV9B7gQ6OZtWeaIjbvSSdqy1waYSysvD35+HV7uA5u+hyFPwY2zLLPImEK4aQrZwZ97RaQrUAto7ebNRWSIiKwWkXUiMr6I510iIioivdy8b6x48/uN/P7jJYjAyO7WFEps11p4exhMvxda9Ibb50Hf2yyzyJgiuLngfYKI1AH+BCQC1YGHi3uRiMQDLwODgGRggYgkqurKAs+rAdwFzC9h7VEtZe9h/vL5SupUTeDqPi1pXMtiLVzLzYYfXoA5T0PFKjDqVTj1SouoMMaFYpuCqr4RvDkHaFuC9+4NrFPVDQAi8iEwElhZ4HmP46zVcG8J3jvqTV4SQBUm3d6fVvXsMknXUpbAlLGwYzl0HgVDn7aICmNKwM3VR8c9KlDVx4p5aTNga8h2MtCnwHv3AFqo6jQRsaYQpKpMWhzgtFZ1rCG4lX0Yvn0SfnwJqjWAy/8LJw/3uypjIo6b00fpIbcrA8OBVS5ed7xjdc1/UCQOeB64odg3ErkVuBWgZcuWLj46sq1I2c/anQf5y6iufpcSGTZ978Rb71kPPa+DQY9Dldp+V2VMRHJz+ujZ0G0ReQZnbKE4yUCLkO3mQErIdg2gK/CtOOd6GwOJIjJCVRcWqGECMAGgV69eSpSblBQgIT6O4ac08buU8JaxD754BBb9OxhRkQhtbcVYY05EaZLVquJubGEB0EFE2gAB4ArgqiMPquo+ID+zQUS+Be4t2BBiTU5uHlOWpHBOpwbUrmrX0Bdq9QxnacyD24MRFQ9CQlW/qzIm4rkZU1jO/077xAMNcAaHi6SqOSIyFpgVfN1bqrpCRB4DFqqqm6ONmPLxgq1M+G4Duw5m2uzlwhxMhZn3wS+fQcMucMV70MwiKowpK26OFEJH63KAHaqa4+bNVXU6ML3AfYUNXA90857RKi9PeeGrtQBc2bsF53Zq6HNFYUYVln0MM8dD1kHnyGDAOJuRbEwZc9MU/qKq14beISLvFrzPnJifN+0hsPcwL1zR3SaqFbR3K0y7G9Z9Ac17w4h/QsNOfldlTFRy0xS6hG6ISAXAjtfL2KTFAaomxDOos11Tny8vDxa+CV8+6hwpDH0aTr/ZZiQb46GiFtm5H3gAqCIi+4/cDWQRvBLIlI2M7FymL3dWVauaYKuqAZC6BqbeBVt+gnbnwvB/QJ1WfldlTNQraj2FJ4EnReRJVb2/HGuKOV+u2sGBzBzG2OBySETFU1CxKoz6F5x6hUVUGFNO3Pyz9GcRqRW8hBQRqQ0MVNXJ3pYWOyYtDtCoZiX6tavndyn+SkmCKXc6ERVdRjuni6rbgLsx5clNSuojRxoCgKruBR7xrqTYsvtgJnPWpDKqe7PYXVUt6xDM/hO8fi6kpzoRFZe+bQ3BGB+4OVI4XuOwE99lZNqybeTkKaN7xugVRxu/c8YO9myAntfDoMcsosIYH7n55b5QRJ7DicFW4E5gkadVxZCJSQFOblKTTo1jbFW1jH3wxcOw6G2o0waunwptzvK7KmNinpumcCfOWgof4Vx9NBu43cuiot3UpSnM27CbnFxl6da9PDgsxlYB+3U6fH4PHNwB/e901kq2iApjwoKbQLx0IH/VNBGpDFwEfOJhXVHrcFYu4z9bhgJVE+Jp26Aao2Jlqc2DqTDjj7BiIjTqCle8D816+l2VMSaEq7GB4CpqFwBXBn/MxPCWAAARo0lEQVR+jzWFUpm9cjvpWbl8eGtf+raNkauNVGHZR8GIinQ49yEnoiK+ot+VGWMKKLIpiMhZOMmmFwI/AwOAtqp6qBxqi0oTFwdoVrsKvVvX9buU8rF3SzCi4kto0ceJqGhwkt9VGWMKUdSM5mRgC/Aq8AdVPSAiG60hlN7OAxl8tzaV3w5sR1y0X36alwcL3nAiKgCG/j0YUeHmKmhjjF+KOlL4DBgFXA7kisgUQlZOMyWXuCSFPIXR0T6GkLoaEu+ErfOh/fkw/HmoHf0r5hkTDQr9Z5uq/g5oDTwHnAOsARqIyGUiUr18yosuk5ICdGtWi/YNa/hdijdys2HO3+FfZ8CuNTD6Nbj6U2sIxkSQIscUVFWBr4GvRaQiMARnsPkVQlZNM8Vbs+MAK1L28/Dwzn6X4o3AYufoYMcv0GUMDH3KZiQbE4Fcz0xW1WxgKjBVRKp4V1J0mrg4QHycMKJ7U79LKVtZh+DbJ+Gnl6B6I7jiA+g0zO+qjDGlVKq4ClU9XNaFRLO8PGXKkgBndahP/eqV/C6n7GycC4l3QdpGOO0GJ6Kici2/qzLGnADLMCoH8zbsZtu+DO6PlpnLh/c6ERWL34G6beH6adDmTL+rMsaUAddNQUSqBWc3mxKamBSgeqUKXBANq6odFVFxFwy83yIqjIkixV40LiL9RWQlsCq4faqIvOJ5ZVHicFYuM5ZvY2jXxlSuGMHLSB7cCZ/cAB9eCVXrwc1fwQWPW0MwJsq4OVJ4HhgMJAKo6tLgTGfjwherdpCelRu50diqsPRDmHW/RVQYEwNcnT5S1a1y9HKIud6UE30mLU6maa3K9G0TgTlHe7fA1HGw/ito0TcYUdHR76qMMR5y0xS2ikh/QEUkAbiL4KkkU7TUA5nMXbuLW89qG1mxFnl5sOB1+PLPztrIw56BXjdZRIUxMcBNU7gNeAFoBiTjrKdwh5dFRYupS1PIzVPGRFKshUVUGBPT3DQFUdWrPa8kCk1KCtClaU06NIqAWIucLPjhBZj7NCRUg9ET4JTLnCMFY0zMcNMUfhSRjTgrr32mqns9rikqrNt5gOWBfTx0YQTMTQgsgil3ws4V0PViGPIUVG/gd1XGGB8Ue5JYVTsADwFdgMUiMk1ErvG8sgg3cXGAOCG8Yy2yDsGsB+GN8+FwGlz5IVzyljUEY2KYq5FDVf1ZVe8BegN7gHc8rSrCObEWKZzZoQENa1T2u5zj2zgXXu3nZBb1vB7umAcnDfW7KmOMz9xMXqspIteLyAzgR2AbTnMwhZi/cQ+BvYcZE45zEw7vdQaS37kIJA5u+Bwu+odlFhljAHdjCkuBycBjqvqTx/VEhUlJyVRLiOeCzo39LuVoq6bB57+H9FQY8DsnoqKiBd4aY/7HTVNoG1xXocREZAjO5azxwBuq+rcCj98D3AzkAKnAjaq6uTSfFS4ysnOZsXw7Q7o2oUpCmMRaHNwJ0/8AKydDo25w1YfQtIffVRljwlBRazT/Q1XHAYkickxTUNURRb2xiMQDLwODcOY3LBCRRFVdGfK0JKCXqh4Skd8CT+Ms/xmxvli5gwOZOeFx6kgVln4AM++H7MNw3sNOiJ1FVBhjClHUkcK7wZ/PlPK9ewPrVHUDgIh8CIwE8puCqn4T8vx5QMRf1TQpKUDjmpXp29bnWIu0zTBtHKz/2iIqjDGuFdoUVHVR8GZ3VX0h9DER+R0wp5j3bgZsDdlOBvoU8fybgBnHe0BEbgVuBWjZMnxn1+46mMmcNancfGYb4v2KtcjLhZ9fh68es4gKY0yJuflNcf1x7rvBxeuO91vxuGMTwXkPvYC/H+9xVZ2gqr1UtVeDBuF7Df3/Yi2a+1PAzl/hrcEw8z5o1R9unwe9b7GGYIxxragxhSuBq4A2IpIY8lANYLeL904GWoRsNwdSjvM55wMPAmeraqabosPVpKQAnZvU5KTG5RxrkZMFP/wD5v4dEqrDmNeh26UWUWGMKbGixhSOzEmoDzwbcv8BYJmL914AdBCRNkAAuAKnyeQTkR7Aa8AQVd1ZgrrDzrqdB1mWvI8Hy3vJTYuoMMaUoaLGFDYDm4F+pXljVc0RkbHALJxLUt9S1RUi8hiwUFUTcU4XVQc+Ca7XsKW4q5rC1aSkZOIERpZXrEXWIfjmCZj3ClRv7ERU2IxkY8wJKnaegoj0Bf4JnAwk4PyCT1fVmsW9VlWnA9ML3PdwyO3zS1qwn/akZ3Hpv35k76HsYx7bn5HNgPb1aVizHGItNsyBqXdB2ibodSOc/6jNSDbGlAk3k9dewjn18wnOYPB1QHsviwpXU5YEWJ+azmW9mpNQ4ejBW0G4/PQWhbyyjBzeC7MfgqR3oW47J6Ki9RnefqYxJqa4XY5znYjEq2ou8G8R+dHjusLSkYHkpy85tfw//KiIinEwcLxFVBhjypybpnAouAznEhF5GmfwuZq3ZYWfIwPJ5b4+woEdMOMPsHIKNO4GV30ETbuXbw3GmJjhpilcizOOMBa4G+cy04u9LCocHRlIHnFqOQ0kq8KS92HWAxZRYYwpN8U2hZCAusPAn70tJzzl5SmTk1I4o0OD8hlITtsMU38HG76Blv2ciIr6Hbz/XGNMzCtq8tpyCpmBDKCqp3hSURhasMlZH+EPg0/y9oPycuHnCcGIiji48Fk47UabkWyMKTdFHSkML7cqwtykpABVE+K5oEsj7z5k56+QOBaSF0CHC+DC56C2x1czGWNMAcVNXot5Gdm5fL58G0O6NqZqgquLtUomJwu+f96JqKhUA8a8Ad0usYgKY4wv3ExeO8D/TiMlABVxOXktGny1aicHMnK8CblLXuQcHexc6WQVDfkbVKtf9p9jjDEuuRloPirdTURGEUNrNE9KSqZRzUr0a1eG6yNkpcPXT8D8V6FGE7jqY+g4uOze3xhjSqnE50NUdbKIjPeimHCz+2Am365O5aYzynB9hA3fQuJdsHezs87B+Y9C5Zg46DLGRAA3p4/GhGzG4URdlGrN5kgzbdk2cvKUUT3KYGnNw2nBiIr3ghEV06H1gBN/X2OMKUNujhQuCrmdA2zCWVYz6k1MCtCpcQ1ObnKC/5JfmQjT74X0XXDG3XD2fRZRYYwJS27GFH5THoWEm/WpB1m6dS8PDOtU+jc5sMNpBqsSofEpcPUn0MSH3CRjjHHJzemjNsCdQOvQ50fqugduTU4KBNdHKMWpo/yIivshO8MZN+g31iIqjDFhz83po8nAm8BUIM/bcsJDXp4yKSnAgPb1aVTSWIu0TTB1XDCioj+MeNEiKowxEcNNU8hQ1Rc9ryRMfLYomWdnryZlXwb3DOro/oV5uTD/Nfj6cZB4Z0byab+xiApjTERx0xReEJFHgNlA5pE7VXWxZ1X5RFV55dt1xMUJN/RvzbBuTdy9cOcqmDIWAguhw2AY/hzU8mCymzHGeMxNU+iGE599Lv87faTB7aiyPLCP9anpPDG6K1f3aVX8C3Ky4PvnYO4zzlyDi9+ErhdbRIUxJmK5aQqjgbaqmuV1MX6blBQgIT6O4d1crJmQvBAS7wxGVFwWjKgow1nPxhjjAzdNYSlQG9jpcS2+ysnNY+rSFM7t1JBaVYu4SuhIRMW8V6BmU4uoMMZEFTdNoRHwq4gs4Ogxhai6JPW7tbvYdTCL0T2LuAR1/TfO4jd7N8PpN8N5j1hEhTEmqrhpCo94XkUYmJgUoHbVipxzUsNjHzycBrMegiXvQb328JsZ0Kp/+RdpjDEeczOjeU55FOKnAxnZzF6xnUt7NSehQoFLSI+KqLgnGFFRDktyGmOMD2w9BWDGL9vJzMljdOiaCQe2ByMqplpEhTEmZth6CsCkxQFa16tKz5a1nYiKpPdg9oOQkxmMqLgT4j1Ydc0YY8JMzK6nMGVJgK9W7USBeRt387vzOiBpm2DaOGfNg1YD4KIXoX57nys1xpjyE5PrKWTl5PFo4gryFOpWS6Br42r8Jm46vPqUE1Ex/HnoeYNFVBhjYk5MrqcwZ00qaYeyefP6XpxXd7czCW3uQug4xMksqlUGi+oYY0wEirn1FH4J7OO9eZtpXFUYuO1N+OQ5i6gwxpigYs+PiMg7IlI7ZLuOiLzl5s1FZIiIrBaRdccbhxCRSiLyUfDx+SLSuiTFl9SP63cx/J/fs3/tjyQmPED83Keg6xi4YwF0u8QagjEm5rk5fXSKqu49sqGqaSLSo7gXiUg88DIwCEgGFohIoqquDHnaTUCaqrYXkSuAp4DLS7QHJZD481oer/we1zADTWgKF38KHQZ59XHGGBNx3DSFOBGpo6ppACJS1+XregPrVHVD8HUf4oxFhDaFkcCjwdufAi+JiKhqmQ9kZ6z5hrG/3kJzSYXTb0HOfwQq1Sj+hcYYE0Pc/HJ/FvhRRD7FueroMuAJF69rBmwN2U4G+hT2HFXNEZF9QD1gl4v3L5Fffl1NHa3AiiEf0aXfkLJ+e2OMiQpuBpr/IyILcdZPEGBMgVNAhTneCfqCRwBunoOI3ArcCtCyZUsXH32stHajeDPtFF7u069UrzfGmFjgavJasAm4aQShkoEWIdvNgZRCnpMsIhWAWsCe43z+BGACQK9evUp1amlQl8YM6tK4NC81xpiY4eXsrAVABxFpIyIJwBVAYoHnJALXB29fAnztxXiCMcYYdzwL9AmOEYwFZgHxwFuqukJEHgMWqmoi8CbwroiswzlCuMKreowxxhTP05Q3VZ0OTC9w38MhtzOAS72swRhjjHsW7mOMMSafNQVjjDH5rCkYY4zJZ03BGGNMPmsKxhhj8kmkTQsQkVRgcylfXh8PIjQigO13bLH9ji1u97uVqjYo7kkR1xROhIgsVNVeftdR3my/Y4vtd2wp6/2200fGGGPyWVMwxhiTL9aawgS/C/CJ7Xdssf2OLWW63zE1pmCMMaZosXakYIwxpggx0xREZIiIrBaRdSIy3u96vCQim0RkuYgsCS6QhIjUFZEvRGRt8Gcdv+s8USLylojsFJFfQu477n6K48Xg979MRHr6V/mJKWS/HxWRQPA7XyIiw0Ieuz+436tFZLA/VZ8YEWkhIt+IyCoRWSEivwveH9XfdxH77d33rapR/wcnuns90BZIAJYCnf2uy8P93QTUL3Df08D44O3xwFN+11kG+3kW0BP4pbj9BIYBM3BW++sLzPe7/jLe70eBe4/z3M7Bv++VgDbB/w/i/d6HUuxzE6Bn8HYNYE1w36L6+y5ivz37vmPlSKE3sE5VN6hqFvAhMNLnmsrbSOCd4O13gFE+1lImVHUux67UV9h+jgT+o455QG0RaVI+lZatQva7MCOBD1U1U1U3Autw/n+IKKq6TVUXB28fAFbhrPEe1d93EftdmBP+vmOlKTQDtoZsJ1P0f9hIp8BsEVkUXN8aoJGqbgPnLxrQ0LfqvFXYfsbC34GxwVMlb4WcHoy6/RaR1kAPYD4x9H0X2G/w6PuOlaYgx7kvmi+7GqCqPYGhwB0icpbfBYWBaP878CrQDugObAOeDd4fVfstItWBz4Bxqrq/qKce575o2m/Pvu9YaQrJQIuQ7eZAik+1eE5VU4I/dwKTcA4fdxw5fA7+3OlfhZ4qbD+j+u+Aqu5Q1VxVzQNe53+nDKJmv0WkIs4vxv+q6sTg3VH/fR9vv738vmOlKSwAOohIGxFJwFkLOtHnmjwhItVEpMaR28AFwC84+3t98GnXA1P8qdBzhe1nInBd8KqUvsC+I6cdokGB8+Wjcb5zcPb7ChGpJCJtgA7Az+Vd34kSEcFZ032Vqj4X8lBUf9+F7ben37ffo+vlOIo/DGfkfj3woN/1eLifbXGuPlgKrDiyr0A94CtgbfBnXb9rLYN9/QDn0Dkb519INxW2nziH1S8Hv//lQC+/6y/j/X43uF/Lgr8YmoQ8/8Hgfq8Ghvpdfyn3+Qyc0yDLgCXBP8Oi/fsuYr89+75tRrMxxph8sXL6yBhjjAvWFIwxxuSzpmCMMSafNQVjjDH5rCkYY4zJZ03BGGNMPmsKxhhj8llTMMYYk+//AU1cK9Xm6HCWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result=pd.DataFrame()\n",
    "df_result[\"contractor_id\"]=contractor_id\n",
    "df_result[\"actual\"]=actual\n",
    "df_result[\"predicted\"]=predicted\n",
    "df_result[\"predicted_prob\"]=predicted_prob\n",
    "df_result=df_result.sort_values(by=[\"predicted_prob\"],ascending=False)\n",
    "df_result[\"Actual_Positive\"]=df_result.apply(lambda x: TP(x[\"actual\"],x[\"predicted\"]),axis=1)\n",
    "df_result[\"Cumulative_Positives\"]=df_result[\"Actual_Positive\"].cumsum()\n",
    "total_positives=df_result[\"Actual_Positive\"].sum()\n",
    "df_result[\"Cumulative_Positives_percent\"]=df_result[\"Cumulative_Positives\"]/total_positives\n",
    "df_result[\"Cumulative_Count\"]=df_result[\"contractor_id\"].expanding().count()/df_result[\"contractor_id\"].count()\n",
    "plt.plot(df_result[\"Cumulative_Positives_percent\"].values.tolist())\n",
    "plt.plot(df_result[\"Cumulative_Count\"].values.tolist())\n",
    "plt.ylabel('cumulative Actual Positives Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window 1 Year (Boosted Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_window_one_year = df_raw.loc[df_raw['applied_in_window_12months_or_not'] != 'Not enough info']\n",
    "x_train = df_window_one_year.loc[df_raw['train_test'] == 1].iloc[:,:56].drop(['Dealer ID','year','train_test','No. of Employees'],axis=1)\n",
    "y_train = df_window_one_year.loc[df_raw['train_test'] == 1].iloc[:,73].astype(int)\n",
    "x_test = df_window_one_year.loc[df_raw['train_test'] == 0].iloc[:,:56].drop(['Dealer ID','year','train_test','No. of Employees'],axis=1)\n",
    "y_test = df_window_one_year.loc[df_raw['train_test'] == 0].iloc[:,73].astype(int)\n",
    "features = [c for c in x_train.columns]\n",
    "categorical_feats = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | max_depth | min_da... | num_le... | threshold |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.623652\tvalid_1's binary_logloss: 0.643861\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[106]\ttraining's binary_logloss: 0.609635\tvalid_1's binary_logloss: 0.66187\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.626027\tvalid_1's binary_logloss: 0.637036\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[159]\ttraining's binary_logloss: 0.606913\tvalid_1's binary_logloss: 0.639253\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.637526\tvalid_1's binary_logloss: 0.671158\n",
      "| \u001b[95m 45      \u001b[0m | \u001b[95m 0.6232  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.2938  \u001b[0m | \u001b[95m 9.329   \u001b[0m | \u001b[95m 118.9   \u001b[0m | \u001b[95m 36.99   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's binary_logloss: 0.621969\tvalid_1's binary_logloss: 0.647525\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.618673\tvalid_1's binary_logloss: 0.657663\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's binary_logloss: 0.623968\tvalid_1's binary_logloss: 0.635202\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's binary_logloss: 0.614977\tvalid_1's binary_logloss: 0.640895\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.615323\tvalid_1's binary_logloss: 0.665374\n",
      "| \u001b[95m 46      \u001b[0m | \u001b[95m 0.6265  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.464   \u001b[0m | \u001b[95m 9.155   \u001b[0m | \u001b[95m 101.5   \u001b[0m | \u001b[95m 108.8   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[99]\ttraining's binary_logloss: 0.623704\tvalid_1's binary_logloss: 0.643157\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[90]\ttraining's binary_logloss: 0.61974\tvalid_1's binary_logloss: 0.662199\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.627036\tvalid_1's binary_logloss: 0.63578\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's binary_logloss: 0.614047\tvalid_1's binary_logloss: 0.638094\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.622286\tvalid_1's binary_logloss: 0.671609\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.6255  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.02805 \u001b[0m | \u001b[0m 5.068   \u001b[0m | \u001b[0m 130.8   \u001b[0m | \u001b[0m 28.33   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[108]\ttraining's binary_logloss: 0.620364\tvalid_1's binary_logloss: 0.641125\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.613785\tvalid_1's binary_logloss: 0.654597\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.615169\tvalid_1's binary_logloss: 0.634198\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[162]\ttraining's binary_logloss: 0.611716\tvalid_1's binary_logloss: 0.637818\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.608117\tvalid_1's binary_logloss: 0.666654\n",
      "| \u001b[95m 48      \u001b[0m | \u001b[95m 0.634   \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.969   \u001b[0m | \u001b[95m 9.942   \u001b[0m | \u001b[95m 86.01   \u001b[0m | \u001b[95m 121.2   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.619658\tvalid_1's binary_logloss: 0.641081\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.613387\tvalid_1's binary_logloss: 0.654815\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's binary_logloss: 0.61372\tvalid_1's binary_logloss: 0.635524\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.614833\tvalid_1's binary_logloss: 0.638429\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.608755\tvalid_1's binary_logloss: 0.666223\n",
      "| \u001b[95m 49      \u001b[0m | \u001b[95m 0.6383  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.844   \u001b[0m | \u001b[95m 9.645   \u001b[0m | \u001b[95m 88.02   \u001b[0m | \u001b[95m 113.0   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's binary_logloss: 0.623077\tvalid_1's binary_logloss: 0.638897\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's binary_logloss: 0.615393\tvalid_1's binary_logloss: 0.656615\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttraining's binary_logloss: 0.624285\tvalid_1's binary_logloss: 0.630386\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[257]\ttraining's binary_logloss: 0.619299\tvalid_1's binary_logloss: 0.636117\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's binary_logloss: 0.616815\tvalid_1's binary_logloss: 0.663547\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.6356  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.875   \u001b[0m | \u001b[0m 4.172   \u001b[0m | \u001b[0m 93.1    \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's binary_logloss: 0.618655\tvalid_1's binary_logloss: 0.639379\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's binary_logloss: 0.614282\tvalid_1's binary_logloss: 0.657557\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's binary_logloss: 0.623658\tvalid_1's binary_logloss: 0.630696\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's binary_logloss: 0.620406\tvalid_1's binary_logloss: 0.636054\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's binary_logloss: 0.618382\tvalid_1's binary_logloss: 0.663497\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.632   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.923   \u001b[0m | \u001b[0m 4.013   \u001b[0m | \u001b[0m 93.08   \u001b[0m | \u001b[0m 120.3   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's binary_logloss: 0.622149\tvalid_1's binary_logloss: 0.635161\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[63]\ttraining's binary_logloss: 0.62325\tvalid_1's binary_logloss: 0.652695\n",
      "fold n°2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's binary_logloss: 0.619477\tvalid_1's binary_logloss: 0.622707\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's binary_logloss: 0.620261\tvalid_1's binary_logloss: 0.627028\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's binary_logloss: 0.611533\tvalid_1's binary_logloss: 0.652912\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.636   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.871   \u001b[0m | \u001b[0m 4.002   \u001b[0m | \u001b[0m 56.09   \u001b[0m | \u001b[0m 22.88   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[73]\ttraining's binary_logloss: 0.629172\tvalid_1's binary_logloss: 0.647551\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's binary_logloss: 0.607282\tvalid_1's binary_logloss: 0.65691\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[222]\ttraining's binary_logloss: 0.614981\tvalid_1's binary_logloss: 0.63361\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[71]\ttraining's binary_logloss: 0.629369\tvalid_1's binary_logloss: 0.642895\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.614369\tvalid_1's binary_logloss: 0.663926\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.6363  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.971   \u001b[0m | \u001b[0m 9.21    \u001b[0m | \u001b[0m 98.92   \u001b[0m | \u001b[0m 125.8   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[94]\ttraining's binary_logloss: 0.624681\tvalid_1's binary_logloss: 0.643965\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.621131\tvalid_1's binary_logloss: 0.658423\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's binary_logloss: 0.615328\tvalid_1's binary_logloss: 0.634155\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.617488\tvalid_1's binary_logloss: 0.641911\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[112]\ttraining's binary_logloss: 0.611487\tvalid_1's binary_logloss: 0.665837\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.6337  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.981   \u001b[0m | \u001b[0m 9.818   \u001b[0m | \u001b[0m 95.41   \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.617386\tvalid_1's binary_logloss: 0.638436\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's binary_logloss: 0.599017\tvalid_1's binary_logloss: 0.65558\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's binary_logloss: 0.610307\tvalid_1's binary_logloss: 0.634078\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's binary_logloss: 0.605402\tvalid_1's binary_logloss: 0.634793\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[91]\ttraining's binary_logloss: 0.611053\tvalid_1's binary_logloss: 0.663889\n",
      "| \u001b[95m 55      \u001b[0m | \u001b[95m 0.6425  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.875   \u001b[0m | \u001b[95m 9.985   \u001b[0m | \u001b[95m 73.69   \u001b[0m | \u001b[95m 107.4   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[232]\ttraining's binary_logloss: 0.624482\tvalid_1's binary_logloss: 0.644546\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[273]\ttraining's binary_logloss: 0.618161\tvalid_1's binary_logloss: 0.656105\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[211]\ttraining's binary_logloss: 0.63013\tvalid_1's binary_logloss: 0.636615\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's binary_logloss: 0.624479\tvalid_1's binary_logloss: 0.638078\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.622338\tvalid_1's binary_logloss: 0.668503\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.6288  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.942   \u001b[0m | \u001b[0m 4.146   \u001b[0m | \u001b[0m 108.2   \u001b[0m | \u001b[0m 128.3   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's binary_logloss: 0.618097\tvalid_1's binary_logloss: 0.635085\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.623298\tvalid_1's binary_logloss: 0.65306\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[206]\ttraining's binary_logloss: 0.62048\tvalid_1's binary_logloss: 0.623383\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's binary_logloss: 0.616782\tvalid_1's binary_logloss: 0.627001\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's binary_logloss: 0.610814\tvalid_1's binary_logloss: 0.653102\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.6379  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.99    \u001b[0m | \u001b[0m 4.136   \u001b[0m | \u001b[0m 50.29   \u001b[0m | \u001b[0m 36.58   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's binary_logloss: 0.617829\tvalid_1's binary_logloss: 0.634859\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.626288\tvalid_1's binary_logloss: 0.652245\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's binary_logloss: 0.617879\tvalid_1's binary_logloss: 0.6234\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[234]\ttraining's binary_logloss: 0.614612\tvalid_1's binary_logloss: 0.62652\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's binary_logloss: 0.609187\tvalid_1's binary_logloss: 0.652733\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.661   \u001b[0m | \u001b[0m 4.155   \u001b[0m | \u001b[0m 43.47   \u001b[0m | \u001b[0m 28.95   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[179]\ttraining's binary_logloss: 0.605355\tvalid_1's binary_logloss: 0.632653\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttraining's binary_logloss: 0.616057\tvalid_1's binary_logloss: 0.65358\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[95]\ttraining's binary_logloss: 0.61816\tvalid_1's binary_logloss: 0.622383\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's binary_logloss: 0.605355\tvalid_1's binary_logloss: 0.6254\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.615131\tvalid_1's binary_logloss: 0.653272\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.6379  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.186   \u001b[0m | \u001b[0m 4.116   \u001b[0m | \u001b[0m 10.06   \u001b[0m | \u001b[0m 24.83   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's binary_logloss: 0.61499\tvalid_1's binary_logloss: 0.633016\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.619971\tvalid_1's binary_logloss: 0.652967\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's binary_logloss: 0.616763\tvalid_1's binary_logloss: 0.621619\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[148]\ttraining's binary_logloss: 0.614959\tvalid_1's binary_logloss: 0.625702\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's binary_logloss: 0.617284\tvalid_1's binary_logloss: 0.654233\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.6363  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.964   \u001b[0m | \u001b[0m 4.033   \u001b[0m | \u001b[0m 10.24   \u001b[0m | \u001b[0m 24.44   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.629196\tvalid_1's binary_logloss: 0.643102\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[78]\ttraining's binary_logloss: 0.617729\tvalid_1's binary_logloss: 0.65486\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's binary_logloss: 0.613138\tvalid_1's binary_logloss: 0.635412\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's binary_logloss: 0.613303\tvalid_1's binary_logloss: 0.636736\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's binary_logloss: 0.612284\tvalid_1's binary_logloss: 0.664575\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.6389  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.987   \u001b[0m | \u001b[0m 9.487   \u001b[0m | \u001b[0m 81.35   \u001b[0m | \u001b[0m 106.5   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's binary_logloss: 0.600115\tvalid_1's binary_logloss: 0.634744\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.622616\tvalid_1's binary_logloss: 0.654169\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's binary_logloss: 0.597728\tvalid_1's binary_logloss: 0.624586\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's binary_logloss: 0.602383\tvalid_1's binary_logloss: 0.618833\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's binary_logloss: 0.614746\tvalid_1's binary_logloss: 0.650877\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5855  \u001b[0m | \u001b[0m 4.025   \u001b[0m | \u001b[0m 21.6    \u001b[0m | \u001b[0m 28.55   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.624526\tvalid_1's binary_logloss: 0.638696\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's binary_logloss: 0.608337\tvalid_1's binary_logloss: 0.652199\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[144]\ttraining's binary_logloss: 0.607917\tvalid_1's binary_logloss: 0.623727\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's binary_logloss: 0.6043\tvalid_1's binary_logloss: 0.632089\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's binary_logloss: 0.604486\tvalid_1's binary_logloss: 0.656142\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.6422  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.856   \u001b[0m | \u001b[0m 9.989   \u001b[0m | \u001b[0m 64.01   \u001b[0m | \u001b[0m 92.41   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's binary_logloss: 0.625684\tvalid_1's binary_logloss: 0.63847\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttraining's binary_logloss: 0.611548\tvalid_1's binary_logloss: 0.651715\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's binary_logloss: 0.60954\tvalid_1's binary_logloss: 0.624346\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[185]\ttraining's binary_logloss: 0.600048\tvalid_1's binary_logloss: 0.631184\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's binary_logloss: 0.607244\tvalid_1's binary_logloss: 0.65591\n",
      "| \u001b[95m 64      \u001b[0m | \u001b[95m 0.6442  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 5.957   \u001b[0m | \u001b[95m 9.333   \u001b[0m | \u001b[95m 62.98   \u001b[0m | \u001b[95m 98.78   \u001b[0m | \u001b[95m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's binary_logloss: 0.618299\tvalid_1's binary_logloss: 0.63386\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's binary_logloss: 0.621801\tvalid_1's binary_logloss: 0.65252\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's binary_logloss: 0.619258\tvalid_1's binary_logloss: 0.622923\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[236]\ttraining's binary_logloss: 0.616899\tvalid_1's binary_logloss: 0.62764\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's binary_logloss: 0.611468\tvalid_1's binary_logloss: 0.653286\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.6376  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.896   \u001b[0m | \u001b[0m 4.437   \u001b[0m | \u001b[0m 58.75   \u001b[0m | \u001b[0m 70.86   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's binary_logloss: 0.618332\tvalid_1's binary_logloss: 0.63458\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's binary_logloss: 0.621424\tvalid_1's binary_logloss: 0.653212\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[186]\ttraining's binary_logloss: 0.621269\tvalid_1's binary_logloss: 0.62346\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's binary_logloss: 0.6173\tvalid_1's binary_logloss: 0.626848\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 50 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's binary_logloss: 0.611529\tvalid_1's binary_logloss: 0.65292\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.6373  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.938   \u001b[0m | \u001b[0m 4.489   \u001b[0m | \u001b[0m 60.62   \u001b[0m | \u001b[0m 91.07   \u001b[0m | \u001b[0m 0.5     \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set parameters\n",
    "'''\n",
    "param = {\n",
    "            'num_leaves': 113,\n",
    "            'min_data_in_leaf': 88, \n",
    "            'objective':'binary',\n",
    "            'max_depth': 9,\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 1,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": 1,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"lambda_l1\": 5.844,\n",
    "            \"verbosity\": -1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's binary_logloss: 0.621015\tvalid_1's binary_logloss: 0.641087\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's binary_logloss: 0.613387\tvalid_1's binary_logloss: 0.654815\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's binary_logloss: 0.613721\tvalid_1's binary_logloss: 0.635524\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.614834\tvalid_1's binary_logloss: 0.638429\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttraining's binary_logloss: 0.608756\tvalid_1's binary_logloss: 0.666223\n",
      "CV score: 0.63893 \n",
      "Test Accuracy:0.65930 \n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run boosted tree\n",
    "'''\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(x_train))\n",
    "predictions = np.zeros(len(x_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                           label=y_train.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                           label=y_train.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(x_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "pred_0_1 = [0]*len(predictions)\n",
    "for i in range(x_train.shape[0]):\n",
    "        if oof[i] >= 0.5:\n",
    "            oof[i] = 1\n",
    "        else:\n",
    "            oof[i] = 0\n",
    "for i in range(len(predictions)):\n",
    "        if predictions[i] >= 0.5:\n",
    "            pred_0_1[i] = 1\n",
    "        else:\n",
    "            pred_0_1[i] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(accuracy_score(oof, y_train.values)))\n",
    "print(\"Test Accuracy:{:<8.5f}\".format(accuracy_score(pred_0_1, y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = confusion_matrix(y_test.values, pred_0_1, labels=None, sample_weight=None)\n",
    "df_matrix,df_summary = metrix_matrix(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_0</th>\n",
       "      <th>pred_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual_0</th>\n",
       "      <td>56</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_1</th>\n",
       "      <td>22</td>\n",
       "      <td>451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred_0  pred_1\n",
       "actual_0      56     240\n",
       "actual_1      22     451"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy</th>\n",
       "      <td>0.659298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PPV</th>\n",
       "      <td>0.652677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NPV</th>\n",
       "      <td>0.717949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sensitivity</th>\n",
       "      <td>0.953488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specificity</th>\n",
       "      <td>0.189189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Value\n",
       "Accuracy     0.659298\n",
       "PPV          0.652677\n",
       "NPV          0.717949\n",
       "Sensitivity  0.953488\n",
       "Specificity  0.189189"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractor_id = df_window_one_year.loc[(df_window_one_year['train_test'] == 0),'Dealer ID'].values\n",
    "actual = y_test.values\n",
    "predicted_prob = np.array(predictions)\n",
    "predicted= pred_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_result=pd.DataFrame()\n",
    "df_result[\"contractor_id\"]=contractor_id\n",
    "df_result[\"actual\"]=actual\n",
    "df_result[\"predicted\"]=predicted\n",
    "df_result[\"predicted_prob\"]=predicted_prob\n",
    "df_result=df_result.sort_values(by=[\"predicted_prob\"],ascending=False)\n",
    "df_result[\"Actual_Positive\"]=df_result.apply(lambda x: TP(x[\"actual\"],x[\"predicted\"]),axis=1)\n",
    "df_result[\"Cumulative_Positives\"]=df_result[\"Actual_Positive\"].cumsum()\n",
    "total_positives=df_result[\"Actual_Positive\"].sum()\n",
    "df_result[\"Cumulative_Positives_percent\"]=df_result[\"Cumulative_Positives\"]/total_positives\n",
    "df_result[\"Cumulative_Count\"]=df_result[\"contractor_id\"].expanding().count()/df_result[\"contractor_id\"].count()\n",
    "plt.plot(df_result[\"Cumulative_Positives_percent\"].values.tolist())\n",
    "plt.plot(df_result[\"Cumulative_Count\"].values.tolist())\n",
    "plt.ylabel('cumulative Actual Positives Percentage')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
