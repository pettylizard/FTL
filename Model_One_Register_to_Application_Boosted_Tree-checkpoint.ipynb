{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import modules\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import gc\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import data\n",
    "'''\n",
    "df_raw = pd.read_csv('./Data_Processed_All_Contractors_Characteristics - Data.csv')\n",
    "df_2016 = df_raw.loc[df_raw['registed 2016'] == 1]\n",
    "df_2016_xy = df_2016.iloc[:,:56].drop(['Dealer ID','No. of Employees',\\\n",
    "                                       'registed 2016','JS 17.Column3',\\\n",
    "                                       'JS 18.Column3','JS 19.Column3',\\\n",
    "                                       'NON USER 17.Column3','NON USER 18.Column3',\\\n",
    "                                       'Velocity 17.Column3','centurty 18.Column3',\\\n",
    "                                       'Gibson 18.Column3'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Converted State-AL', 'Converted State-AR', 'Converted State-CA',\n",
       "       'Converted State-FL', 'Converted State-GA', 'Converted State-IL',\n",
       "       'Converted State-IN', 'Converted State-KY', 'Converted State-LA',\n",
       "       'Converted State-MI', 'Converted State-MO', 'Converted State-NC',\n",
       "       'Converted State-NJ', 'Converted State-OH', 'Converted State-Others',\n",
       "       'Converted State-PA', 'Converted State-SC', 'Converted State-TN',\n",
       "       'Converted State-TX', 'employeebucket-NA', 'employeebucket-4~8',\n",
       "       'employeebucket-<4', 'employeebucket->8', 'Sales between 0-99,999',\n",
       "       'Sales between 100,000-499,999', 'Other Sales', 'Sales N/A',\n",
       "       'Currently offers Consumer Financing?_No',\n",
       "       'Currently offers Consumer Financing?_Yes',\n",
       "       'Currently offers Consumer Financing?_N/A', 'Over 10', 'Below 10',\n",
       "       'No year info', 'Hitting Potential 16.Column3', 'JS 16.Column3',\n",
       "       'NON USER 16.Column3', 'brand_1', 'brand_2', 'brand_3', 'brand_4',\n",
       "       'brand_5', 'brand_6', 'brand_7', 'brand_8', 'applied 2016'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2016_xy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "clarify target and x variables (features and categorical features)\n",
    "'''\n",
    "y = df_2016_xy['applied 2016']\n",
    "features = [c for c in df_2016_xy.columns if c not in ['applied 2016']]\n",
    "x = df_2016_xy.drop(['applied 2016'],axis=1)\n",
    "categorical_feats = [c for c in df_2016_xy.columns if c != 'applied 2016']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "split training data and testing data\n",
    "'''\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set one function with different parameters to do parameters optimization\n",
    "'''\n",
    "def lgb_cv(num_leaves,\n",
    "           min_data_in_leaf,\n",
    "           max_depth,\n",
    "           feature_fraction,\n",
    "           bagging_fraction,\n",
    "           lambda_l1,\n",
    "          threshold):\n",
    "    folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "    oof = np.zeros(x_train.shape[0])\n",
    "    for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "        print(\"fold n°{}\".format(fold_))\n",
    "        trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                               label=y_train.iloc[trn_idx],\n",
    "                               categorical_feature=categorical_feats\n",
    "                              )\n",
    "        val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                               label=y_train.iloc[val_idx],\n",
    "                               categorical_feature=categorical_feats\n",
    "                              )\n",
    "        param = {\n",
    "            'num_leaves': int(num_leaves),\n",
    "            'min_data_in_leaf': int(min_data_in_leaf), \n",
    "            'objective':'binary',\n",
    "            'max_depth': int(max_depth),\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": feature_fraction,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": bagging_fraction ,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"lambda_l1\": lambda_l1,\n",
    "            \"verbosity\": -1\n",
    "        }\n",
    "    \n",
    "        clf = lgb.train(param,\n",
    "                        trn_data,\n",
    "                        10000,\n",
    "                        valid_sets = [trn_data, val_data],\n",
    "                        verbose_eval=500,\n",
    "                        early_stopping_rounds = 200)\n",
    "        \n",
    "        oof[val_idx] = clf.predict(x_train.iloc[val_idx][features],\n",
    "                                   num_iteration=clf.best_iteration)\n",
    "        del clf, trn_idx, val_idx\n",
    "        gc.collect()\n",
    "    \n",
    "    for i in range(x_train.shape[0]):\n",
    "        if oof[i] >= threshold:\n",
    "            oof[i] = 1\n",
    "        else:\n",
    "            oof[i] = 0\n",
    "\n",
    "    return accuracy_score(oof, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "use bayesian optimization to find the optimal parameters in ranges\n",
    "'''\n",
    "LGB_BO = BayesianOptimization(lgb_cv, {\n",
    "    'num_leaves': (5, 130),\n",
    "    'min_data_in_leaf': (10, 150),\n",
    "    'max_depth': (4, 10),\n",
    "    'feature_fraction': (1,1),\n",
    "    'bagging_fraction': (1,1),\n",
    "    'lambda_l1': (0, 6),\n",
    "    'threshold':(0.4,0.6),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | max_depth | min_da... | num_le... | threshold |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.634733\tvalid_1's binary_logloss: 0.669459\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's binary_logloss: 0.630043\tvalid_1's binary_logloss: 0.658083\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's binary_logloss: 0.617798\tvalid_1's binary_logloss: 0.671702\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's binary_logloss: 0.646248\tvalid_1's binary_logloss: 0.688062\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.635845\tvalid_1's binary_logloss: 0.659303\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5696  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.9     \u001b[0m | \u001b[0m 6.583   \u001b[0m | \u001b[0m 40.74   \u001b[0m | \u001b[0m 102.5   \u001b[0m | \u001b[0m 0.5045  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's binary_logloss: 0.644825\tvalid_1's binary_logloss: 0.675395\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.633999\tvalid_1's binary_logloss: 0.662952\n",
      "Early stopping, best iteration is:\n",
      "[471]\ttraining's binary_logloss: 0.634781\tvalid_1's binary_logloss: 0.66255\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.625644\tvalid_1's binary_logloss: 0.675966\n",
      "Early stopping, best iteration is:\n",
      "[459]\ttraining's binary_logloss: 0.626549\tvalid_1's binary_logloss: 0.675323\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.685971\tvalid_1's binary_logloss: 0.695181\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's binary_logloss: 0.651868\tvalid_1's binary_logloss: 0.667514\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.196   \u001b[0m | \u001b[0m 9.358   \u001b[0m | \u001b[0m 133.0   \u001b[0m | \u001b[0m 67.72   \u001b[0m | \u001b[0m 0.5479  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's binary_logloss: 0.603062\tvalid_1's binary_logloss: 0.674536\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's binary_logloss: 0.566346\tvalid_1's binary_logloss: 0.657479\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.604373\tvalid_1's binary_logloss: 0.681737\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's binary_logloss: 0.606455\tvalid_1's binary_logloss: 0.6826\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's binary_logloss: 0.58119\tvalid_1's binary_logloss: 0.678034\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.5246  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.2758  \u001b[0m | \u001b[0m 9.827   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[53]\ttraining's binary_logloss: 0.651813\tvalid_1's binary_logloss: 0.660408\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's binary_logloss: 0.641383\tvalid_1's binary_logloss: 0.656759\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's binary_logloss: 0.636589\tvalid_1's binary_logloss: 0.666971\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.651149\tvalid_1's binary_logloss: 0.68874\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.638934\tvalid_1's binary_logloss: 0.665634\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5594  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.4     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's binary_logloss: 0.649567\tvalid_1's binary_logloss: 0.673853\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's binary_logloss: 0.652465\tvalid_1's binary_logloss: 0.669126\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's binary_logloss: 0.645507\tvalid_1's binary_logloss: 0.6748\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's binary_logloss: 0.671513\tvalid_1's binary_logloss: 0.694038\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's binary_logloss: 0.655106\tvalid_1's binary_logloss: 0.666931\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 129.9   \u001b[0m | \u001b[0m 130.0   \u001b[0m | \u001b[0m 0.4     \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[113]\ttraining's binary_logloss: 0.641102\tvalid_1's binary_logloss: 0.673376\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[138]\ttraining's binary_logloss: 0.64475\tvalid_1's binary_logloss: 0.665329\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's binary_logloss: 0.635566\tvalid_1's binary_logloss: 0.675634\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.658013\tvalid_1's binary_logloss: 0.69039\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's binary_logloss: 0.63988\tvalid_1's binary_logloss: 0.657397\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5679  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 4.0     \u001b[0m | \u001b[0m 66.98   \u001b[0m | \u001b[0m 65.63   \u001b[0m | \u001b[0m 0.4102  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's binary_logloss: 0.63076\tvalid_1's binary_logloss: 0.670084\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's binary_logloss: 0.638054\tvalid_1's binary_logloss: 0.661798\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[149]\ttraining's binary_logloss: 0.62761\tvalid_1's binary_logloss: 0.676223\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's binary_logloss: 0.661951\tvalid_1's binary_logloss: 0.692305\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[170]\ttraining's binary_logloss: 0.634992\tvalid_1's binary_logloss: 0.656838\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5586  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.988   \u001b[0m | \u001b[0m 9.983   \u001b[0m | \u001b[0m 56.71   \u001b[0m | \u001b[0m 87.71   \u001b[0m | \u001b[0m 0.5363  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's binary_logloss: 0.647836\tvalid_1's binary_logloss: 0.67551\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's binary_logloss: 0.652272\tvalid_1's binary_logloss: 0.663717\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[296]\ttraining's binary_logloss: 0.644204\tvalid_1's binary_logloss: 0.674507\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.686343\tvalid_1's binary_logloss: 0.695179\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.646859\tvalid_1's binary_logloss: 0.666385\n",
      "Early stopping, best iteration is:\n",
      "[304]\ttraining's binary_logloss: 0.647037\tvalid_1's binary_logloss: 0.666124\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5526  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.377   \u001b[0m | \u001b[0m 4.086   \u001b[0m | \u001b[0m 148.9   \u001b[0m | \u001b[0m 5.752   \u001b[0m | \u001b[0m 0.5593  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.634089\tvalid_1's binary_logloss: 0.66144\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's binary_logloss: 0.631349\tvalid_1's binary_logloss: 0.653855\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttraining's binary_logloss: 0.630894\tvalid_1's binary_logloss: 0.667178\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's binary_logloss: 0.655722\tvalid_1's binary_logloss: 0.68896\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[115]\ttraining's binary_logloss: 0.624368\tvalid_1's binary_logloss: 0.660649\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5637  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.002   \u001b[0m | \u001b[0m 4.094   \u001b[0m | \u001b[0m 10.09   \u001b[0m | \u001b[0m 63.82   \u001b[0m | \u001b[0m 0.4842  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.635273\tvalid_1's binary_logloss: 0.669744\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[261]\ttraining's binary_logloss: 0.607289\tvalid_1's binary_logloss: 0.649853\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttraining's binary_logloss: 0.639\tvalid_1's binary_logloss: 0.675761\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.659218\tvalid_1's binary_logloss: 0.691694\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[88]\ttraining's binary_logloss: 0.632001\tvalid_1's binary_logloss: 0.654029\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.5772  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.0912  \u001b[0m | \u001b[95m 4.039   \u001b[0m | \u001b[95m 67.18   \u001b[0m | \u001b[95m 101.2   \u001b[0m | \u001b[95m 0.5595  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[184]\ttraining's binary_logloss: 0.632512\tvalid_1's binary_logloss: 0.671871\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's binary_logloss: 0.643824\tvalid_1's binary_logloss: 0.664215\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's binary_logloss: 0.638313\tvalid_1's binary_logloss: 0.675618\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.657838\tvalid_1's binary_logloss: 0.690358\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[198]\ttraining's binary_logloss: 0.639431\tvalid_1's binary_logloss: 0.657604\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5637  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.933   \u001b[0m | \u001b[0m 4.064   \u001b[0m | \u001b[0m 61.1    \u001b[0m | \u001b[0m 110.4   \u001b[0m | \u001b[0m 0.5633  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.630448\tvalid_1's binary_logloss: 0.655923\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.619629\tvalid_1's binary_logloss: 0.63895\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.6291\tvalid_1's binary_logloss: 0.667348\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.640324\tvalid_1's binary_logloss: 0.682191\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's binary_logloss: 0.62445\tvalid_1's binary_logloss: 0.661617\n",
      "| \u001b[95m 12      \u001b[0m | \u001b[95m 0.5798  \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 0.09078 \u001b[0m | \u001b[95m 4.077   \u001b[0m | \u001b[95m 38.04   \u001b[0m | \u001b[95m 81.9    \u001b[0m | \u001b[95m 0.517   \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[290]\ttraining's binary_logloss: 0.634357\tvalid_1's binary_logloss: 0.669727\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.631529\tvalid_1's binary_logloss: 0.657262\n",
      "Early stopping, best iteration is:\n",
      "[491]\ttraining's binary_logloss: 0.631873\tvalid_1's binary_logloss: 0.656802\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's binary_logloss: 0.639341\tvalid_1's binary_logloss: 0.675862\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.685551\tvalid_1's binary_logloss: 0.695068\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.628702\tvalid_1's binary_logloss: 0.665098\n",
      "Early stopping, best iteration is:\n",
      "[459]\ttraining's binary_logloss: 0.630085\tvalid_1's binary_logloss: 0.66509\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5552  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.004711\u001b[0m | \u001b[0m 4.321   \u001b[0m | \u001b[0m 149.3   \u001b[0m | \u001b[0m 102.9   \u001b[0m | \u001b[0m 0.507   \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[107]\ttraining's binary_logloss: 0.635129\tvalid_1's binary_logloss: 0.67622\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.609162\tvalid_1's binary_logloss: 0.650191\n",
      "Early stopping, best iteration is:\n",
      "[572]\ttraining's binary_logloss: 0.604721\tvalid_1's binary_logloss: 0.649354\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[56]\ttraining's binary_logloss: 0.644693\tvalid_1's binary_logloss: 0.68439\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.645327\tvalid_1's binary_logloss: 0.69289\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[143]\ttraining's binary_logloss: 0.633694\tvalid_1's binary_logloss: 0.663474\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5637  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.09188 \u001b[0m | \u001b[0m 4.075   \u001b[0m | \u001b[0m 90.4    \u001b[0m | \u001b[0m 6.892   \u001b[0m | \u001b[0m 0.47    \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[35]\ttraining's binary_logloss: 0.639154\tvalid_1's binary_logloss: 0.664178\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's binary_logloss: 0.593832\tvalid_1's binary_logloss: 0.639928\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's binary_logloss: 0.629011\tvalid_1's binary_logloss: 0.669034\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's binary_logloss: 0.642806\tvalid_1's binary_logloss: 0.682555\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's binary_logloss: 0.620742\tvalid_1's binary_logloss: 0.662005\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5747  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.04817 \u001b[0m | \u001b[0m 4.055   \u001b[0m | \u001b[0m 41.56   \u001b[0m | \u001b[0m 97.9    \u001b[0m | \u001b[0m 0.4701  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's binary_logloss: 0.660452\tvalid_1's binary_logloss: 0.677294\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.609881\tvalid_1's binary_logloss: 0.650609\n",
      "Early stopping, best iteration is:\n",
      "[548]\ttraining's binary_logloss: 0.607177\tvalid_1's binary_logloss: 0.649472\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's binary_logloss: 0.64736\tvalid_1's binary_logloss: 0.685041\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's binary_logloss: 0.651631\tvalid_1's binary_logloss: 0.691191\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[177]\ttraining's binary_logloss: 0.633448\tvalid_1's binary_logloss: 0.662273\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5611  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.02112 \u001b[0m | \u001b[0m 4.441   \u001b[0m | \u001b[0m 103.3   \u001b[0m | \u001b[0m 87.65   \u001b[0m | \u001b[0m 0.5263  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[61]\ttraining's binary_logloss: 0.625301\tvalid_1's binary_logloss: 0.665311\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttraining's binary_logloss: 0.603719\tvalid_1's binary_logloss: 0.651969\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[58]\ttraining's binary_logloss: 0.621075\tvalid_1's binary_logloss: 0.672884\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[15]\ttraining's binary_logloss: 0.653602\tvalid_1's binary_logloss: 0.692881\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[101]\ttraining's binary_logloss: 0.614814\tvalid_1's binary_logloss: 0.658039\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.5628  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 4.084   \u001b[0m | \u001b[0m 48.22   \u001b[0m | \u001b[0m 37.8    \u001b[0m | \u001b[0m 0.5766  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[172]\ttraining's binary_logloss: 0.643226\tvalid_1's binary_logloss: 0.674435\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.630591\tvalid_1's binary_logloss: 0.659255\n",
      "Early stopping, best iteration is:\n",
      "[641]\ttraining's binary_logloss: 0.626291\tvalid_1's binary_logloss: 0.658227\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's binary_logloss: 0.639127\tvalid_1's binary_logloss: 0.676488\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[5]\ttraining's binary_logloss: 0.685573\tvalid_1's binary_logloss: 0.695071\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's binary_logloss: 0.640787\tvalid_1's binary_logloss: 0.663423\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.5501  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.09925 \u001b[0m | \u001b[0m 4.017   \u001b[0m | \u001b[0m 145.8   \u001b[0m | \u001b[0m 38.94   \u001b[0m | \u001b[0m 0.5698  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's binary_logloss: 0.63584\tvalid_1's binary_logloss: 0.671638\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.633605\tvalid_1's binary_logloss: 0.656484\n",
      "Early stopping, best iteration is:\n",
      "[581]\ttraining's binary_logloss: 0.631462\tvalid_1's binary_logloss: 0.655766\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's binary_logloss: 0.639802\tvalid_1's binary_logloss: 0.675184\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's binary_logloss: 0.686791\tvalid_1's binary_logloss: 0.695185\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.631134\tvalid_1's binary_logloss: 0.663734\n",
      "Early stopping, best iteration is:\n",
      "[499]\ttraining's binary_logloss: 0.631148\tvalid_1's binary_logloss: 0.663719\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5518  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.5702  \u001b[0m | \u001b[0m 9.056   \u001b[0m | \u001b[0m 148.0   \u001b[0m | \u001b[0m 129.6   \u001b[0m | \u001b[0m 0.5885  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[72]\ttraining's binary_logloss: 0.642401\tvalid_1's binary_logloss: 0.677046\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[500]\ttraining's binary_logloss: 0.609908\tvalid_1's binary_logloss: 0.653473\n",
      "Early stopping, best iteration is:\n",
      "[697]\ttraining's binary_logloss: 0.599294\tvalid_1's binary_logloss: 0.650342\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's binary_logloss: 0.645907\tvalid_1's binary_logloss: 0.682869\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's binary_logloss: 0.649672\tvalid_1's binary_logloss: 0.693762\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[124]\ttraining's binary_logloss: 0.636887\tvalid_1's binary_logloss: 0.663994\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5772  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.07186 \u001b[0m | \u001b[0m 4.056   \u001b[0m | \u001b[0m 94.49   \u001b[0m | \u001b[0m 128.7   \u001b[0m | \u001b[0m 0.4085  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's binary_logloss: 0.637478\tvalid_1's binary_logloss: 0.668266\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's binary_logloss: 0.639739\tvalid_1's binary_logloss: 0.661377\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[191]\ttraining's binary_logloss: 0.632722\tvalid_1's binary_logloss: 0.669207\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's binary_logloss: 0.630075\tvalid_1's binary_logloss: 0.690029\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's binary_logloss: 0.641499\tvalid_1's binary_logloss: 0.659897\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5688  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.824   \u001b[0m | \u001b[0m 4.035   \u001b[0m | \u001b[0m 54.31   \u001b[0m | \u001b[0m 5.847   \u001b[0m | \u001b[0m 0.4653  \u001b[0m |\n",
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's binary_logloss: 0.646741\tvalid_1's binary_logloss: 0.663173\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's binary_logloss: 0.638935\tvalid_1's binary_logloss: 0.653074\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's binary_logloss: 0.630879\tvalid_1's binary_logloss: 0.666294\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's binary_logloss: 0.642278\tvalid_1's binary_logloss: 0.68944\n",
      "fold n°4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's binary_logloss: 0.633757\tvalid_1's binary_logloss: 0.661204\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5739  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.935   \u001b[0m | \u001b[0m 4.144   \u001b[0m | \u001b[0m 31.75   \u001b[0m | \u001b[0m 78.24   \u001b[0m | \u001b[0m 0.42    \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=2, n_iter=20, acq='ei', xi=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "set parameters\n",
    "'''\n",
    "param = {\n",
    "            'num_leaves': 81,\n",
    "            'min_data_in_leaf': 38, \n",
    "            'objective':'binary',\n",
    "            'max_depth': 4,\n",
    "            'learning_rate': 0.05,\n",
    "            \"boosting\": \"gbdt\",\n",
    "            \"feature_fraction\": 1,\n",
    "            \"bagging_freq\": 1,\n",
    "            \"bagging_fraction\": 1,\n",
    "            \"bagging_seed\": 11,\n",
    "            \"lambda_l1\": 0.09078,\n",
    "            \"verbosity\": -1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's binary_logloss: 0.630448\tvalid_1's binary_logloss: 0.655923\n",
      "fold n°1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:1186: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n",
      "C:\\Users\\wuziy\\Anaconda3\\lib\\site-packages\\lightgbm\\basic.py:752: UserWarning: categorical_feature in param dict is overridden.\n",
      "  warnings.warn('categorical_feature in param dict is overridden.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[93]\ttraining's binary_logloss: 0.619629\tvalid_1's binary_logloss: 0.63895\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's binary_logloss: 0.6291\tvalid_1's binary_logloss: 0.667348\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's binary_logloss: 0.640324\tvalid_1's binary_logloss: 0.682191\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "run boosted tree\n",
    "'''\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(x_train))\n",
    "predictions = np.zeros(len(x_test))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(x_train.values, y_train.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(x_train.iloc[trn_idx][features],\n",
    "                           label=y_train.iloc[trn_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "    val_data = lgb.Dataset(x_train.iloc[val_idx][features],\n",
    "                           label=y_train.iloc[val_idx],\n",
    "                           categorical_feature=categorical_feats\n",
    "                          )\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param,\n",
    "                    trn_data,\n",
    "                    num_round,\n",
    "                    valid_sets = [trn_data, val_data],\n",
    "                    verbose_eval=500,\n",
    "                    early_stopping_rounds = 200)\n",
    "    \n",
    "    oof[val_idx] = clf.predict(x_train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(x_test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "        if oof[i] >= 0.5:\n",
    "            oof[i] = 1\n",
    "        else:\n",
    "            oof[i] = 0\n",
    "for i in range(len(predictions)):\n",
    "        if predictions[i] >= 0.5:\n",
    "            predictions[i] = 1\n",
    "        else:\n",
    "            predictions[i] = 0\n",
    "print(\"CV score: {:<8.5f}\".format(accuracy_score(oof, y_train.values)))\n",
    "print(\"Test Accuracy:{:<8.5f}\".format(accuracy_score(predictions, y_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0.,\n",
       "       1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "       0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1.,\n",
       "       1., 0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,\n",
       "       0., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1.,\n",
       "       1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "       1., 1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1.,\n",
       "       0., 0., 0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 0., 0.,\n",
       "       1., 0., 1., 1., 0., 1.])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77, 62],\n",
       "       [62, 94]], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.values, predictions, labels=None, sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
